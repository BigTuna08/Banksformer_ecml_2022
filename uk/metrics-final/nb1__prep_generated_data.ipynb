{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excessive-triumph",
   "metadata": {},
   "source": [
    "# Notes:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "interracial-validation",
   "metadata": {},
   "source": [
    "This notebook is only tested for czech data generated by Banksformer. Parts of it may be useful with other data, but no guarantees.\n",
    "\n",
    "The goal of this notebook is to ensure generated datasets have the correct columns so they can be used to compute results. \n",
    "\n",
    "Specifically, for each transaction we need:\n",
    "\n",
    "1 - 'datetime' \n",
    "2 - 'raw_amount'\n",
    "3 - At least one of: \n",
    "  -- (A) columns for each code in 'cat_code_fields' or \n",
    "  -- (B) tcode column which is a concatination of the codes in 'cat_code_fields'\n",
    "  -- (C) tcode column with 'shortnames' and information in 'codenames.py' for converting (deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prospective-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "floral-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_dir = \"generated_data/\" # process all .csv files from this directory\n",
    "to_dir = \"generated_data/\"   # write all updated .csv files to this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03188307-b189-4368-83d6-752c338c0d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37caa405-0ec4-41ac-a90a-4cc630dbed32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb2957-20e9-455b-876f-b9a1e8fa463c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ce0868-a6de-4137-b553-97313f7b087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_code_fields(df, cat_code_fields = CAT_CODE_FIELDS):\n",
    "    \n",
    "#     df[cat_code_fields] = df.raw_tcode.str.split(TCODE_SEP, expand=True)\n",
    "    \n",
    "#     if convert_shortnames:\n",
    "        \n",
    "#         if \"tcode\" not in df.columns:\n",
    "#             print(\"No 'tcode' field found, skipping convert_shortnames\")\n",
    "            \n",
    "#         else:\n",
    "#             from codenames import code_names as raw_code_names\n",
    "\n",
    "#             # code_names = [(x, y.replace(\"-\", TCODE_SEP)) for x,y in raw_code_names]\n",
    "            \n",
    "#             code_names = [(x, TCODE_SEP.join([y.split(\"-\")[i] for i in [1,2,0]])) for x,y in raw_code_names]\n",
    "#             short_to_long_names = dict(code_names)\n",
    "\n",
    "#             df[\"short_tcode\"] = df[\"tcode\"]\n",
    "#             df[\"raw_tcode\"] = df.tcode.apply(lambda x: short_to_long_names[x])\n",
    "\n",
    "#             df[\"tcode\"] = df[\"raw_tcode\"]  # just added\n",
    "\n",
    "#     elif \"tcode\" in df.columns:\n",
    "#         df[\"raw_tcode\"] = df[\"tcode\"]\n",
    "\n",
    "\n",
    "\n",
    "#     # if all parts of tcode exist, create tcode col\n",
    "#     if all([x in df.columns for x in cat_code_fields]):\n",
    "\n",
    "#         set_tcode(df, cat_code_fields)\n",
    "\n",
    "#         # if there was a tcode col, check it agrees with the newly created tcode\n",
    "#         if \"raw_tcode\" in df.columns:\n",
    "\n",
    "#             if not all(df.raw_tcode == df.tcode):\n",
    "#                 print(\"Warning! tcode field doesn't match the concatinated codes!!\", file=sys.stderr)\n",
    "#                 print(\"Check where df.raw_tcode != df.tcode!\", file=sys.stderr)\n",
    "#                 print(\"Using concatinated codes version ...\", file=sys.stderr)  \n",
    "                \n",
    "#                 if raise_if_nonmatch:\n",
    "#                     raise Exception(\"df.raw_tcode != df.tcode\")\n",
    "\n",
    "#     # otherwise, if there is a tcode, split it into parts\n",
    "#     elif \"raw_tcode\" in df.columns:\n",
    "#         df[cat_code_fields] = df.raw_tcode.str.split(TCODE_SEP, expand=True)\n",
    "\n",
    "#     else:\n",
    "#         raise Exception(\"Dataframe must have either 'tcode' column, or all columns in 'cat_code_fields'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b727f1-af92-42fd-bc85-e6c4fdf0e86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a95a7f-3820-4655-94aa-e0d6287c4cea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bibliographic-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: These methods are only valid for czech data! \n",
    "from mylib.preprocessing import set_code_fields\n",
    "from mylib.dataset_params import TCODE_SEP, CAT_CODE_FIELDS\n",
    "\n",
    "def set_datetime(df):\n",
    "    \n",
    "    if not \"datetime\" in df.columns:\n",
    "        \n",
    "        df[\"datetime\"] = df[\"date\"]\n",
    "        \n",
    "        \n",
    "    if not \"td\" in df.columns:\n",
    "        \n",
    "        df[\"td\"] = df[\"days_passed\"]\n",
    "        \n",
    "        \n",
    " \n",
    "def set_raw_amount(df):\n",
    "    df[\"raw_amount\"] = df.amount * df.type.apply(lambda x: -1 if x.upper() == \"DEBIT\" else 1)  \n",
    "    \n",
    "\n",
    "def set_codes(df):\n",
    "    pass\n",
    "\n",
    "def set_tcode(df, cat_code_fields = CAT_CODE_FIELDS):\n",
    "    tcode = df[cat_code_fields[0]].astype(str)\n",
    "    for ccf in cat_code_fields[1:]:\n",
    "        tcode += TCODE_SEP + df[ccf].astype(str)\n",
    "\n",
    "    df[\"tcode\"] = tcode\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def prep_df(df):\n",
    "    # set_code_fields(df)\n",
    "    set_tcode(df)\n",
    "    set_datetime(df)\n",
    "    set_raw_amount(df)\n",
    "    set_codes(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09860c3d-9064-48d7-9893-41ce05d1eeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "structured-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.dataset_params import CAT_CODE_FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "otherwise-hawaii",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description', 'flag', 'type']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_CODE_FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-thriller",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b6090d55-2c78-4123-8e5f-ad6f26276e49",
   "metadata": {},
   "source": [
    "all([x not in df.columns for x in CAT_CODE_FIELDS])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69a95045-ec7f-4ea2-bc58-ca5363f625d8",
   "metadata": {},
   "source": [
    "all([x + \"_num\" in df.columns for x in CAT_CODE_FIELDS])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0e60891-4f48-4e97-b765-cd47b78b411a",
   "metadata": {},
   "source": [
    "[x + \"_num\" in df.columns for x in CAT_CODE_FIELDS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6790f7c-ba84-4fe2-af80-2d77d3820084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e4e327be-fb1c-4955-a656-81e0cbcaa5d7",
   "metadata": {},
   "source": [
    "if not (all([x in df.columns for x in CAT_CODE_FIELDS]) or (\"raw_tcode\" in df.columns ) or \"tcode\" in df.columns):\n",
    "    if all([x + \"_num\" in df.columns for x in CAT_CODE_FIELDS]):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd141702-0901-48bf-801e-280ced8557cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1b17d33-74d0-44c6-9dd0-209aceeffde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On tg_1-hd_24-nl_4-bs_64--len_20.csv\n",
      "\n",
      "\n",
      "On gen_v2b-v__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-v__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On .DS_Store\n",
      "\n",
      "\n",
      "On sqrt-log_var__gen_v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64-len_25-v2.csv\n",
      "Updated: sqrt-log_var__gen_v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64-len_25-v2.csv\n",
      "\n",
      "\n",
      "On tg_2-hd_24-nl_4-bs_64--len_20.csv\n",
      "\n",
      "\n",
      "On dg_data_new.csv\n",
      "\n",
      "\n",
      "On updated_dfs.txt\n",
      "\n",
      "\n",
      "On sqrt-log_var__gen_v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64-len_25-v2.csv\n",
      "Updated: sqrt-log_var__gen_v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64-len_25-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-v__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nc__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nd__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nd__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On .ipynb_checkpoints\n",
      "\n",
      "\n",
      "On gen_v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nc__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On tg_0-hd_24-nl_4-bs_64--len_20.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nd__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b-nc__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n",
      "On gen_v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "failed_on = []\n",
    "\n",
    "\n",
    "if 'updated_dfs.txt' in os.listdir(\"generated_data/\"):\n",
    "    with open(\"generated_data/updated_dfs.txt\") as f:\n",
    "        already_updated = [line.strip() for line in f.readlines()]\n",
    "\n",
    "else: \n",
    "    with open(\"generated_data/updated_dfs.txt\", 'w') as f:\n",
    "        already_updated = []\n",
    "    \n",
    "\n",
    "    \n",
    "with open(\"generated_data/updated_dfs.txt\", \"a\") as f: \n",
    "    \n",
    "\n",
    "\n",
    "    for fname in os.listdir(from_dir):\n",
    "        path = from_dir + fname\n",
    "        \n",
    "        print(\"On\", fname)\n",
    "\n",
    "        if not \".csv\" in fname or fname in already_updated:\n",
    "            print(\"\\n\")\n",
    "            continue \n",
    "            \n",
    "            \n",
    "        if not fname[0] == \"s\":\n",
    "            continue\n",
    "\n",
    "\n",
    "#         if  \"f-cz\" in fname: #\"v2a\" in fname or\n",
    "#             convert_shortnames = True\n",
    "#         else:\n",
    "#             convert_shortnames = False\n",
    "        # convert_shortnames = False\n",
    "\n",
    "    \n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # if \"tcode\" in df.columns:\n",
    "        #     convert_shortnames = 'interest_cr' in df.tcode.unique()\n",
    "        # else:\n",
    "        #     convert_shortnames = False\n",
    "        \n",
    "        # if \"gen_v2a__\" in fname:\n",
    "        #     try:\n",
    "        #         df = df.drop(columns=[\"tcode\", \"raw_tcode\"])\n",
    "        #         print(\"dropped:\",\"tcode\", \"raw_tcode\")\n",
    "        #     except:\n",
    "        #         print(\"Didnt drop:\",\"tcode\", \"raw_tcode\")\n",
    "        \n",
    "        if True:\n",
    "        # try:\n",
    "            prep_df(df)\n",
    "            \n",
    "#             if not \"datetime\" in df.columns:\n",
    "#                 df[\"datetime\"] = df[\"date\"]\n",
    "        \n",
    "        \n",
    "            # if \"CREDIT\" in df.k_symbol.unique():\n",
    "            #     df.rename(columns={'k_symbol': 'type', 'operation': 'k_symbol', 'type':'operation'}, inplace=True)\n",
    "            \n",
    "        \n",
    "            df.to_csv(to_dir + fname, index=False)\n",
    "            print(\"Updated:\", fname)\n",
    "        # except Exception as e:\n",
    "        #     failed_on.append((fname, e, df))\n",
    "        #     print(f\"Failed to update: {path}. ({e})\", )\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        f.writelines(fname+\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c97cfc0-3e51-44ff-a729-7099f81530ab",
   "metadata": {},
   "source": [
    "\n",
    "failed_on = []\n",
    "\n",
    "\n",
    "if 'updated_dfs.txt' in os.listdir(\"generated_data/\"):\n",
    "    with open(\"generated_data/updated_dfs.txt\") as f:\n",
    "        already_updated = [line.strip() for line in f.readlines()]\n",
    "\n",
    "else: \n",
    "    with open(\"generated_data/updated_dfs.txt\", 'w') as f:\n",
    "        already_updated = []\n",
    "    \n",
    "\n",
    "    \n",
    "with open(\"generated_data/updated_dfs.txt\", \"a\") as f: \n",
    "    \n",
    "\n",
    "\n",
    "    for fname in os.listdir(from_dir):\n",
    "        path = from_dir + fname\n",
    "\n",
    "        if not \".csv\" in fname or fname in already_updated:\n",
    "            continue \n",
    "\n",
    "\n",
    "        # if \"v2a\" in fname or \"f-cz\" in fname:\n",
    "        #     convert_shortnames = True\n",
    "        # else:\n",
    "        #     convert_shortnames = False\n",
    "        \n",
    "        convert_shortnames = False\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        # if True:\n",
    "        try:\n",
    "            prep_df(df, convert_shortnames)\n",
    "        \n",
    "        \n",
    "            if \"CREDIT\" in df.k_symbol.unique():\n",
    "                df.rename(columns={'k_symbol': 'type', 'operation': 'k_symbol', 'type':'operation'}, inplace=True)\n",
    "            \n",
    "        \n",
    "            df.to_csv(to_dir + fname, index=False)\n",
    "            print(\"Updated:\", fname)\n",
    "        except Exception as e:\n",
    "            failed_on.append((fname, e, df))\n",
    "            print(f\"Failed to update: {path}. ({e})\", )\n",
    "\n",
    "        print(\"\\n\")\n",
    "\n",
    "        f.writelines(fname+\"\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dde73da-dc7d-4564-adda-3fcfab4fc3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gen_v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--vf1-len_20-v2.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bde05bef-782c-404a-a56f-24de28f25cd3",
   "metadata": {},
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1cd37fc-ec21-402f-a0ab-a0efd4a19dff",
   "metadata": {},
   "source": [
    "\"aaaaa\".replace(\"a\", \"B\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8434f8a9-d8bb-4e5f-8ee2-36cff0567e35",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9bbb908d-c544-4948-b536-3ec8f4eb84ce",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8f4f780-d31f-430e-9b53-d4402ad1f3f0",
   "metadata": {},
   "source": [
    "pd.read_csv(\"generated_data/v2a-gen_nld_4-d_model_32-num_heads_4-i_0-dr_0__1-dff_32-opt_adam-l_loss_mse_lwi-0--vf1-len_80-v2.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7628ad53-7861-4f3e-840b-c3cc37d1019c",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"generated_data/v2b-gen_nld_4-d_model_32-num_heads_4-i_0-dr_0__1-dff_32-opt_adam-l_loss_mse_lwi-moredate--vf1-len_80-v2.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e07b773-05d5-4f29-9308-7f2e5252af21",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3601d3e-3a1e-4d7f-a9d2-e5da58fce770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46846c-3d7b-4131-bc0c-0f28fc9ce144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
