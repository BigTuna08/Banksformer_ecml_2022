{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook trains Banksformer models and generates sythetic data.   \n",
    "Parameters for generating data (seq_len, number of seqs) are near bottom (Under \"Generate Full dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)  # suppress warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input dataset and nb_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_KEY_ORDER is ['tcode_num', 'dow', 'month', 'day', 'dtme', 'td_sc', 'log_amount_sc']\n",
      "LOSS_TYPES are: day - scce, dtme - scce, dow - scce, month - scce, td_sc - pdf, log_amount_sc - pdf, tcode_num - scce\n",
      "If this is not correct, edit field_config.py and re-run notebook\n"
     ]
    }
   ],
   "source": [
    "from field_config import CLOCK_DIMS, get_field_info, DATA_KEY_ORDER, LOSS_TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_suffix = \"-uk\"\n",
    "nb_id = \"cond\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6983, 21, 54), (6983, 20, 7), (6983,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tensor = np.load(f\"stored_data/inp_tensor-{ds_suffix}.npy\")\n",
    "tar_tensor = np.load(f\"stored_data/tar_tensor-{ds_suffix}.npy\")\n",
    "attributes = np.load(f\"stored_data/attributes-{ds_suffix}.npy\")\n",
    "\n",
    "inp_tensor.shape, tar_tensor.shape, attributes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seqs, n_steps, n_feat_inp = inp_tensor.shape\n",
    "n_feat_tar = tar_tensor.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_lib.encoding import load_data_encoder\n",
    "data_encoder = load_data_encoder(ds_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and create tf dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_cv, inds_tr, inds_cv, targ_tr, targ_cv = train_test_split(\n",
    "    inp_tensor, np.arange(n_seqs), tar_tensor, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-29 11:56:27.712714: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=(TensorSpec(shape=(21, 54), dtype=tf.float32, name=None), TensorSpec(shape=(20, 7), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tr = tf.data.Dataset.from_tensor_slices((x_tr.astype(np.float32), targ_tr.astype(np.float32)))\n",
    "ds_cv = tf.data.Dataset.from_tensor_slices((x_cv.astype(np.float32), targ_cv.astype(np.float32)))\n",
    "\n",
    "ds_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_lib.transformer_core import make_batches\n",
    "\n",
    "BUFFER_SIZE = ds_tr.cardinality().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.math.log(2. * np.pi)\n",
    "    return  -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_pdf_gen(sample, mean, logvar, raxis=1):\n",
    "    log2pi = tf.cast(tf.math.log(2. * np.pi), tf.float64)\n",
    "    return  -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, MeanSquaredError, SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "loss_scce_logit = SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "loss_scce_probit = SparseCategoricalCrossentropy(\n",
    "    from_logits=False, reduction='none')\n",
    "\n",
    "loss_mse = MeanSquaredError(reduction='none')\n",
    "\n",
    "\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(tf.reduce_sum(seq, axis=2), 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    loss_parts = []\n",
    "    loss_parts_weighted = []\n",
    "\n",
    "    for k, k_pred in pred.items():\n",
    "\n",
    "        st = FIELD_STARTS_TAR[k]\n",
    "        end = st + FIELD_DIMS_TAR[k]\n",
    "        loss_type = LOSS_TYPES[k]\n",
    "        \n",
    "\n",
    "        if loss_type == \"scce\":\n",
    "            loss_ = loss_scce_logit(real[:, :, st:end], k_pred)\n",
    "        elif loss_type == \"clock\":\n",
    "            loss_ = loss_scce_probit(real[:, :, st:end], clock_to_onehot(k, k_pred))\n",
    "        elif loss_type == \"mse\":\n",
    "            loss_ = loss_mse(real[:, :, st:end], k_pred)\n",
    "        elif loss_type == \"pdf\":\n",
    "            loss_ = -log_normal_pdf(real[:, :, st:end], k_pred[:,:,0:1], k_pred[:,:,1:2])[:,:,0]\n",
    "        else:\n",
    "            raise Exception(f\"Invalid loss type! Got loss type = {loss_type} with key = {k}. Check field_config.py for loss types\")\n",
    "            \n",
    "\n",
    "        mask = tf.math.logical_not(tf.math.equal(tf.reduce_sum(real, axis=2), 0))\n",
    "        mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "        loss_ *= mask\n",
    "        loss_ = tf.reduce_sum(loss_)/tf.reduce_sum(mask) \n",
    "\n",
    "        loss_parts.append(loss_)\n",
    "        loss_parts_weighted.append(loss_ * LOSS_WEIGHTS[k])\n",
    "\n",
    "    return tf.reduce_sum(loss_parts_weighted), loss_parts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'day': 31, 'dtme': 31, 'dow': 7, 'month': 12}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_lib.encoding import bulk_encode_time_value\n",
    "\n",
    "EPS_CLOCKP = 0.01\n",
    "\n",
    "CLOCKS = {}\n",
    "for k, val in CLOCK_DIMS.items():\n",
    "    CLOCKS[k] = tf.constant(bulk_encode_time_value(np.arange(val), val), dtype=tf.float32)\n",
    "\n",
    "def clock_to_probs(pt, pts):\n",
    "    \n",
    "    ds = tf.constant(pts) - pt\n",
    "    sq_ds = np.sum(tf.square(ds+EPS_CLOCKP), axis=1)\n",
    "    raw_ps = 1/ sq_ds   \n",
    "    \n",
    "    return raw_ps / np.sum(raw_ps)\n",
    "\n",
    "\n",
    "\n",
    "def clock_to_onehot(k, vals):\n",
    "    orig_shape = vals.shape\n",
    "\n",
    "    vals = tf.reshape(vals, (-1, orig_shape[-1]))\n",
    "\n",
    "    return np.array([clock_to_probs(p, CLOCKS[k]) for p in vals]).reshape(*orig_shape[:-1], -1)   \n",
    "\n",
    "\n",
    "CLOCK_DIMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Banksformer configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVATIONS = {\n",
    "    \"td_sc\": \"relu\",\n",
    "    \"log_amount_sc\": \"relu\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "FIELD_DIMS_IN, FIELD_STARTS_IN, FIELD_DIMS_TAR, FIELD_STARTS_TAR, FIELD_DIMS_NET, FIELD_STARTS_NET = get_field_info(ds_suffix)\n",
    "\n",
    "config[\"ORDER\"] = DATA_KEY_ORDER\n",
    "config[\"FIELD_STARTS_IN\"] = FIELD_STARTS_IN\n",
    "config[\"FIELD_DIMS_IN\"] = FIELD_DIMS_IN\n",
    "config[\"FIELD_STARTS_NET\"] = FIELD_STARTS_NET\n",
    "config[\"FIELD_DIMS_NET\"] = FIELD_DIMS_NET\n",
    "\n",
    "\n",
    "config[\"ACTIVATIONS\"] = ACTIVATIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:56\n",
      "Begin running v2b__nld_4-dm_128-nh_2-i_0-dr_0.1-opt_adam-lwi_0-bs_64\n",
      "Epoch 1 Batch 0 Loss 12.0507\n",
      "Epoch 1 Batch 50 Loss 10.5404\n",
      "Epoch 1 Loss 10.1559\n",
      "** on validation data loss is 9.3292\n",
      "Not recording acc: 'Transformer' object has no attribute 'acc_function'\n",
      "Time taken for 1 epoch: 98.31 secs\n",
      "\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-1\n",
      "Epoch 2 Batch 0 Loss 9.3089\n",
      "Epoch 2 Batch 50 Loss 9.2354\n",
      "Epoch 2 Loss 8.9652\n",
      "** on validation data loss is 7.0959\n",
      "Time taken for 1 epoch: 100.06 secs\n",
      "\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-2\n",
      "Epoch 3 Batch 0 Loss 7.0371\n",
      "Epoch 3 Batch 50 Loss 7.2459\n",
      "Epoch 3 Loss 7.1521\n",
      "** on validation data loss is 6.8766\n",
      "Time taken for 1 epoch: 114.98 secs\n",
      "\n",
      "Saving checkpoint for epoch 3 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-3\n",
      "Epoch 4 Batch 0 Loss 6.7960\n",
      "Epoch 4 Batch 50 Loss 6.8877\n",
      "Epoch 4 Loss 6.8305\n",
      "** on validation data loss is 6.7172\n",
      "Time taken for 1 epoch: 97.66 secs\n",
      "\n",
      "Saving checkpoint for epoch 4 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-4\n",
      "Epoch 5 Batch 0 Loss 6.7142\n",
      "Epoch 5 Batch 50 Loss 6.6954\n",
      "Epoch 5 Loss 6.6485\n",
      "** on validation data loss is 6.6321\n",
      "Time taken for 1 epoch: 110.00 secs\n",
      "\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-5\n",
      "Epoch 6 Batch 0 Loss 6.7439\n",
      "Epoch 6 Batch 50 Loss 6.5610\n",
      "Epoch 6 Loss 6.5227\n",
      "** on validation data loss is 6.4657\n",
      "Time taken for 1 epoch: 108.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 6 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-6\n",
      "Epoch 7 Batch 0 Loss 6.5407\n",
      "Epoch 7 Batch 50 Loss 6.4211\n",
      "Epoch 7 Loss 6.4058\n",
      "** on validation data loss is 6.3817\n",
      "Time taken for 1 epoch: 103.99 secs\n",
      "\n",
      "Saving checkpoint for epoch 7 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-7\n",
      "Epoch 8 Batch 0 Loss 6.3740\n",
      "Epoch 8 Batch 50 Loss 6.3247\n",
      "Epoch 8 Loss 6.2918\n",
      "** on validation data loss is 6.2647\n",
      "Time taken for 1 epoch: 96.99 secs\n",
      "\n",
      "Saving checkpoint for epoch 8 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-8\n",
      "Epoch 9 Batch 0 Loss 6.2769\n",
      "Epoch 9 Batch 50 Loss 6.2037\n",
      "Epoch 9 Loss 6.1866\n",
      "** on validation data loss is 6.1398\n",
      "Time taken for 1 epoch: 97.26 secs\n",
      "\n",
      "Saving checkpoint for epoch 9 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-9\n",
      "Epoch 10 Batch 0 Loss 6.1952\n",
      "Epoch 10 Batch 50 Loss 6.1198\n",
      "Epoch 10 Loss 6.1002\n",
      "** on validation data loss is 6.0522\n",
      "Time taken for 1 epoch: 103.64 secs\n",
      "\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-10\n",
      "Epoch 11 Batch 0 Loss 6.0979\n",
      "Epoch 11 Batch 50 Loss 6.0393\n",
      "Epoch 11 Loss 6.0250\n",
      "** on validation data loss is 6.0205\n",
      "Time taken for 1 epoch: 61.06 secs\n",
      "\n",
      "Saving checkpoint for epoch 11 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-11\n",
      "Epoch 12 Batch 0 Loss 5.9031\n",
      "Epoch 12 Batch 50 Loss 5.9757\n",
      "Epoch 12 Loss 5.9626\n",
      "** on validation data loss is 5.8799\n",
      "Time taken for 1 epoch: 62.49 secs\n",
      "\n",
      "Saving checkpoint for epoch 12 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-12\n",
      "Epoch 13 Batch 0 Loss 5.8732\n",
      "Epoch 13 Batch 50 Loss 5.9049\n",
      "Epoch 13 Loss 5.9027\n",
      "** on validation data loss is 5.8583\n",
      "Time taken for 1 epoch: 83.19 secs\n",
      "\n",
      "Saving checkpoint for epoch 13 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-13\n",
      "Epoch 14 Batch 0 Loss 5.9342\n",
      "Epoch 14 Batch 50 Loss 5.8643\n",
      "Epoch 14 Loss 5.8492\n",
      "** on validation data loss is 5.8068\n",
      "Time taken for 1 epoch: 55.32 secs\n",
      "\n",
      "Saving checkpoint for epoch 14 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-14\n",
      "Epoch 15 Batch 0 Loss 5.6979\n",
      "Epoch 15 Batch 50 Loss 5.8099\n",
      "Epoch 15 Loss 5.8072\n",
      "** on validation data loss is 5.7537\n",
      "Time taken for 1 epoch: 56.75 secs\n",
      "\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-15\n",
      "Epoch 16 Batch 0 Loss 5.6831\n",
      "Epoch 16 Batch 50 Loss 5.7668\n",
      "Epoch 16 Loss 5.7629\n",
      "** on validation data loss is 5.7306\n",
      "Time taken for 1 epoch: 59.24 secs\n",
      "\n",
      "Saving checkpoint for epoch 16 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-16\n",
      "Epoch 17 Batch 0 Loss 5.7260\n",
      "Epoch 17 Batch 50 Loss 5.7241\n",
      "Epoch 17 Loss 5.7234\n",
      "** on validation data loss is 5.7168\n",
      "Time taken for 1 epoch: 56.08 secs\n",
      "\n",
      "Saving checkpoint for epoch 17 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-17\n",
      "Epoch 18 Batch 0 Loss 5.7722\n",
      "Epoch 18 Batch 50 Loss 5.6890\n",
      "Epoch 18 Loss 5.6860\n",
      "** on validation data loss is 5.7325\n",
      "Time taken for 1 epoch: 56.31 secs\n",
      "\n",
      "Saving checkpoint for epoch 18 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-18\n",
      "Epoch 19 Batch 0 Loss 5.8062\n",
      "Epoch 19 Batch 50 Loss 5.6622\n",
      "Epoch 19 Loss 5.6529\n",
      "** on validation data loss is 5.6295\n",
      "Time taken for 1 epoch: 60.66 secs\n",
      "\n",
      "Saving checkpoint for epoch 19 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-19\n",
      "Epoch 20 Batch 0 Loss 5.6841\n",
      "Epoch 20 Batch 50 Loss 5.6315\n",
      "Epoch 20 Loss 5.6198\n",
      "** on validation data loss is 5.6076\n",
      "Time taken for 1 epoch: 55.98 secs\n",
      "\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-20\n",
      "Epoch 21 Batch 0 Loss 5.6958\n",
      "Epoch 21 Batch 50 Loss 5.6137\n",
      "Epoch 21 Loss 5.5936\n",
      "** on validation data loss is 5.5824\n",
      "Time taken for 1 epoch: 50.74 secs\n",
      "\n",
      "Saving checkpoint for epoch 21 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-21\n",
      "Epoch 22 Batch 0 Loss 5.5078\n",
      "Epoch 22 Batch 50 Loss 5.5664\n",
      "Epoch 22 Loss 5.5691\n",
      "** on validation data loss is 5.5972\n",
      "Time taken for 1 epoch: 57.39 secs\n",
      "\n",
      "Saving checkpoint for epoch 22 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-22\n",
      "Epoch 23 Batch 0 Loss 5.6891\n",
      "Epoch 23 Batch 50 Loss 5.5449\n",
      "Epoch 23 Loss 5.5496\n",
      "** on validation data loss is 5.5648\n",
      "Time taken for 1 epoch: 55.75 secs\n",
      "\n",
      "Saving checkpoint for epoch 23 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-23\n",
      "Epoch 24 Batch 0 Loss 5.5421\n",
      "Epoch 24 Batch 50 Loss 5.5332\n",
      "Epoch 24 Loss 5.5296\n",
      "** on validation data loss is 5.5349\n",
      "Time taken for 1 epoch: 57.59 secs\n",
      "\n",
      "Saving checkpoint for epoch 24 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-24\n",
      "Epoch 25 Batch 0 Loss 5.4992\n",
      "Epoch 25 Batch 50 Loss 5.5010\n",
      "Epoch 25 Loss 5.5011\n",
      "** on validation data loss is 5.5179\n",
      "Time taken for 1 epoch: 52.13 secs\n",
      "\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-25\n",
      "Epoch 26 Batch 0 Loss 5.6191\n",
      "Epoch 26 Batch 50 Loss 5.4910\n",
      "Epoch 26 Loss 5.4797\n",
      "** on validation data loss is 5.4557\n",
      "Time taken for 1 epoch: 49.69 secs\n",
      "\n",
      "Saving checkpoint for epoch 26 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-26\n",
      "Epoch 27 Batch 0 Loss 5.4872\n",
      "Epoch 27 Batch 50 Loss 5.4610\n",
      "Epoch 27 Loss 5.4540\n",
      "** on validation data loss is 5.5098\n",
      "Time taken for 1 epoch: 51.11 secs\n",
      "\n",
      "Saving checkpoint for epoch 27 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-27\n",
      "Epoch 28 Batch 0 Loss 5.5023\n",
      "Epoch 28 Batch 50 Loss 5.4232\n",
      "Epoch 28 Loss 5.4287\n",
      "** on validation data loss is 5.4270\n",
      "Time taken for 1 epoch: 48.05 secs\n",
      "\n",
      "Saving checkpoint for epoch 28 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-28\n",
      "Epoch 29 Batch 0 Loss 5.4869\n",
      "Epoch 29 Batch 50 Loss 5.3991\n",
      "Epoch 29 Loss 5.4044\n",
      "** on validation data loss is 5.4231\n",
      "Time taken for 1 epoch: 48.67 secs\n",
      "\n",
      "Saving checkpoint for epoch 29 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-29\n",
      "Epoch 30 Batch 0 Loss 5.4371\n",
      "Epoch 30 Batch 50 Loss 5.3832\n",
      "Epoch 30 Loss 5.3819\n",
      "** on validation data loss is 5.3816\n",
      "Time taken for 1 epoch: 49.81 secs\n",
      "\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-30\n",
      "Epoch 31 Batch 0 Loss 5.3590\n",
      "Epoch 31 Batch 50 Loss 5.3575\n",
      "Epoch 31 Loss 5.3606\n",
      "** on validation data loss is 5.3799\n",
      "Time taken for 1 epoch: 50.69 secs\n",
      "\n",
      "Saving checkpoint for epoch 31 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-31\n",
      "Epoch 32 Batch 0 Loss 5.3886\n",
      "Epoch 32 Batch 50 Loss 5.3484\n",
      "Epoch 32 Loss 5.3396\n",
      "** on validation data loss is 5.3704\n",
      "Time taken for 1 epoch: 30.53 secs\n",
      "\n",
      "Saving checkpoint for epoch 32 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-32\n",
      "Epoch 33 Batch 0 Loss 5.3537\n",
      "Epoch 33 Batch 50 Loss 5.3189\n",
      "Epoch 33 Loss 5.3196\n",
      "** on validation data loss is 5.3987\n",
      "Time taken for 1 epoch: 27.36 secs\n",
      "\n",
      "Saving checkpoint for epoch 33 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-33\n",
      "Epoch 34 Batch 0 Loss 5.4137\n",
      "Epoch 34 Batch 50 Loss 5.3064\n",
      "Epoch 34 Loss 5.3091\n",
      "** on validation data loss is 5.3462\n",
      "Time taken for 1 epoch: 28.19 secs\n",
      "\n",
      "Saving checkpoint for epoch 34 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-34\n",
      "Epoch 35 Batch 0 Loss 5.2605\n",
      "Epoch 35 Batch 50 Loss 5.2827\n",
      "Epoch 35 Loss 5.2868\n",
      "** on validation data loss is 5.3286\n",
      "Time taken for 1 epoch: 27.99 secs\n",
      "\n",
      "Saving checkpoint for epoch 35 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-35\n",
      "Epoch 36 Batch 0 Loss 5.3119\n",
      "Epoch 36 Batch 50 Loss 5.2595\n",
      "Epoch 36 Loss 5.2741\n",
      "** on validation data loss is 5.2981\n",
      "Time taken for 1 epoch: 27.43 secs\n",
      "\n",
      "Saving checkpoint for epoch 36 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-36\n",
      "Epoch 37 Batch 0 Loss 5.3271\n",
      "Epoch 37 Batch 50 Loss 5.2664\n",
      "Epoch 37 Loss 5.2579\n",
      "** on validation data loss is 5.2919\n",
      "Time taken for 1 epoch: 27.50 secs\n",
      "\n",
      "Saving checkpoint for epoch 37 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-37\n",
      "Epoch 38 Batch 0 Loss 5.3666\n",
      "Epoch 38 Batch 50 Loss 5.2377\n",
      "Epoch 38 Loss 5.2494\n",
      "** on validation data loss is 5.3564\n",
      "Time taken for 1 epoch: 27.20 secs\n",
      "\n",
      "Saving checkpoint for epoch 38 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-38\n",
      "Epoch 39 Batch 0 Loss 5.3322\n",
      "Epoch 39 Batch 50 Loss 5.2255\n",
      "Epoch 39 Loss 5.2339\n",
      "** on validation data loss is 5.2961\n",
      "Time taken for 1 epoch: 27.01 secs\n",
      "\n",
      "Stopping early, last 2 val losses are: [<tf.Tensor: shape=(), dtype=float32, numpy=5.3563995>, <tf.Tensor: shape=(), dtype=float32, numpy=5.296116>]                       \n",
      "Best was 5.292\n",
      "\n",
      "\n",
      "Wrote transformer.results to training_history/v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64.pickle\n",
      "12:37\n",
      "Begin running v2b__nld_4-dm_128-nh_2-i_1-dr_0.1-opt_adam-lwi_0-bs_64\n",
      "Epoch 1 Batch 0 Loss 13.0305\n",
      "Epoch 1 Batch 50 Loss 10.2116\n",
      "Epoch 1 Loss 9.9750\n",
      "** on validation data loss is 9.4497\n",
      "Not recording acc: 'Transformer' object has no attribute 'acc_function'\n",
      "Time taken for 1 epoch: 30.93 secs\n",
      "\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-1\n",
      "Epoch 2 Batch 0 Loss 9.3848\n",
      "Epoch 2 Batch 50 Loss 9.1981\n",
      "Epoch 2 Loss 9.0871\n",
      "** on validation data loss is 9.0726\n",
      "Time taken for 1 epoch: 28.32 secs\n",
      "\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-2\n",
      "Epoch 3 Batch 0 Loss 9.0002\n",
      "Epoch 3 Batch 50 Loss 8.2248\n",
      "Epoch 3 Loss 7.7189\n",
      "** on validation data loss is 6.9679\n",
      "Time taken for 1 epoch: 28.62 secs\n",
      "\n",
      "Saving checkpoint for epoch 3 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-3\n",
      "Epoch 4 Batch 0 Loss 6.9679\n",
      "Epoch 4 Batch 50 Loss 6.8370\n",
      "Epoch 4 Loss 6.7789\n",
      "** on validation data loss is 6.9446\n",
      "Time taken for 1 epoch: 28.81 secs\n",
      "\n",
      "Saving checkpoint for epoch 4 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-4\n",
      "Epoch 5 Batch 0 Loss 7.0129\n",
      "Epoch 5 Batch 50 Loss 6.6327\n",
      "Epoch 5 Loss 6.5800\n",
      "** on validation data loss is 6.4174\n",
      "Time taken for 1 epoch: 28.99 secs\n",
      "\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-5\n",
      "Epoch 6 Batch 0 Loss 6.3261\n",
      "Epoch 6 Batch 50 Loss 6.4270\n",
      "Epoch 6 Loss 6.3974\n",
      "** on validation data loss is 6.2923\n",
      "Time taken for 1 epoch: 28.87 secs\n",
      "\n",
      "Saving checkpoint for epoch 6 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-6\n",
      "Epoch 7 Batch 0 Loss 6.2275\n",
      "Epoch 7 Batch 50 Loss 6.2890\n",
      "Epoch 7 Loss 6.2549\n",
      "** on validation data loss is 6.2299\n",
      "Time taken for 1 epoch: 29.57 secs\n",
      "\n",
      "Saving checkpoint for epoch 7 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-7\n",
      "Epoch 8 Batch 0 Loss 6.3549\n",
      "Epoch 8 Batch 50 Loss 6.1757\n",
      "Epoch 8 Loss 6.1605\n",
      "** on validation data loss is 6.1117\n",
      "Time taken for 1 epoch: 28.97 secs\n",
      "\n",
      "Saving checkpoint for epoch 8 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-8\n",
      "Epoch 9 Batch 0 Loss 6.0846\n",
      "Epoch 9 Batch 50 Loss 6.0681\n",
      "Epoch 9 Loss 6.0599\n",
      "** on validation data loss is 5.9922\n",
      "Time taken for 1 epoch: 29.12 secs\n",
      "\n",
      "Saving checkpoint for epoch 9 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-9\n",
      "Epoch 10 Batch 0 Loss 5.8409\n",
      "Epoch 10 Batch 50 Loss 6.0004\n",
      "Epoch 10 Loss 5.9821\n",
      "** on validation data loss is 5.8978\n",
      "Time taken for 1 epoch: 31.45 secs\n",
      "\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-10\n",
      "Epoch 11 Batch 0 Loss 5.8883\n",
      "Epoch 11 Batch 50 Loss 5.9306\n",
      "Epoch 11 Loss 5.9099\n",
      "** on validation data loss is 5.9113\n",
      "Time taken for 1 epoch: 35.68 secs\n",
      "\n",
      "Saving checkpoint for epoch 11 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-11\n",
      "Epoch 12 Batch 0 Loss 5.9187\n",
      "Epoch 12 Batch 50 Loss 5.8620\n",
      "Epoch 12 Loss 5.8526\n",
      "** on validation data loss is 5.8498\n",
      "Time taken for 1 epoch: 39.87 secs\n",
      "\n",
      "Saving checkpoint for epoch 12 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-12\n",
      "Epoch 13 Batch 0 Loss 5.8263\n",
      "Epoch 13 Batch 50 Loss 5.7971\n",
      "Epoch 13 Loss 5.7860\n",
      "** on validation data loss is 5.7490\n",
      "Time taken for 1 epoch: 34.84 secs\n",
      "\n",
      "Saving checkpoint for epoch 13 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-13\n",
      "Epoch 14 Batch 0 Loss 5.8730\n",
      "Epoch 14 Batch 50 Loss 5.7298\n",
      "Epoch 14 Loss 5.7373\n",
      "** on validation data loss is 5.6737\n",
      "Time taken for 1 epoch: 33.27 secs\n",
      "\n",
      "Saving checkpoint for epoch 14 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-14\n",
      "Epoch 15 Batch 0 Loss 5.5382\n",
      "Epoch 15 Batch 50 Loss 5.6992\n",
      "Epoch 15 Loss 5.6830\n",
      "** on validation data loss is 5.6607\n",
      "Time taken for 1 epoch: 32.13 secs\n",
      "\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-15\n",
      "Epoch 16 Batch 0 Loss 5.6335\n",
      "Epoch 16 Batch 50 Loss 5.6528\n",
      "Epoch 16 Loss 5.6399\n",
      "** on validation data loss is 5.6316\n",
      "Time taken for 1 epoch: 32.63 secs\n",
      "\n",
      "Saving checkpoint for epoch 16 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-16\n",
      "Epoch 17 Batch 0 Loss 5.6387\n",
      "Epoch 17 Batch 50 Loss 5.5937\n",
      "Epoch 17 Loss 5.5894\n",
      "** on validation data loss is 5.5354\n",
      "Time taken for 1 epoch: 32.54 secs\n",
      "\n",
      "Saving checkpoint for epoch 17 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-17\n",
      "Epoch 18 Batch 0 Loss 5.5447\n",
      "Epoch 18 Batch 50 Loss 5.5437\n",
      "Epoch 18 Loss 5.5379\n",
      "** on validation data loss is 5.5483\n",
      "Time taken for 1 epoch: 31.43 secs\n",
      "\n",
      "Saving checkpoint for epoch 18 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-18\n",
      "Epoch 19 Batch 0 Loss 5.5689\n",
      "Epoch 19 Batch 50 Loss 5.5006\n",
      "Epoch 19 Loss 5.4948\n",
      "** on validation data loss is 5.4980\n",
      "Time taken for 1 epoch: 32.11 secs\n",
      "\n",
      "Saving checkpoint for epoch 19 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-19\n",
      "Epoch 20 Batch 0 Loss 5.5238\n",
      "Epoch 20 Batch 50 Loss 5.4567\n",
      "Epoch 20 Loss 5.4524\n",
      "** on validation data loss is 5.4243\n",
      "Time taken for 1 epoch: 31.81 secs\n",
      "\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-20\n",
      "Epoch 21 Batch 0 Loss 5.3971\n",
      "Epoch 21 Batch 50 Loss 5.4094\n",
      "Epoch 21 Loss 5.4126\n",
      "** on validation data loss is 5.4608\n",
      "Time taken for 1 epoch: 31.05 secs\n",
      "\n",
      "Saving checkpoint for epoch 21 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-21\n",
      "Epoch 22 Batch 0 Loss 5.4898\n",
      "Epoch 22 Batch 50 Loss 5.3876\n",
      "Epoch 22 Loss 5.3832\n",
      "** on validation data loss is 5.4545\n",
      "Time taken for 1 epoch: 30.80 secs\n",
      "\n",
      "Stopping early, last 2 val losses are: [<tf.Tensor: shape=(), dtype=float32, numpy=5.4608192>, <tf.Tensor: shape=(), dtype=float32, numpy=5.454503>]                       \n",
      "Best was 5.424\n",
      "\n",
      "\n",
      "Wrote transformer.results to training_history/v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64.pickle\n",
      "12:48\n",
      "Begin running v2b__nld_4-dm_128-nh_2-i_2-dr_0.1-opt_adam-lwi_0-bs_64\n",
      "Epoch 1 Batch 0 Loss 12.2463\n",
      "Epoch 1 Batch 50 Loss 9.3061\n",
      "Epoch 1 Loss 8.6866\n",
      "** on validation data loss is 7.7910\n",
      "Not recording acc: 'Transformer' object has no attribute 'acc_function'\n",
      "Time taken for 1 epoch: 31.16 secs\n",
      "\n",
      "Saving checkpoint for epoch 1 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-1\n",
      "Epoch 2 Batch 0 Loss 7.7308\n",
      "Epoch 2 Batch 50 Loss 7.3310\n",
      "Epoch 2 Loss 7.1933\n",
      "** on validation data loss is 6.8355\n",
      "Time taken for 1 epoch: 32.10 secs\n",
      "\n",
      "Saving checkpoint for epoch 2 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-2\n",
      "Epoch 3 Batch 0 Loss 6.9438\n",
      "Epoch 3 Batch 50 Loss 6.8459\n",
      "Epoch 3 Loss 6.8099\n",
      "** on validation data loss is 6.6656\n",
      "Time taken for 1 epoch: 32.29 secs\n",
      "\n",
      "Saving checkpoint for epoch 3 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-3\n",
      "Epoch 4 Batch 0 Loss 6.7803\n",
      "Epoch 4 Batch 50 Loss 6.6727\n",
      "Epoch 4 Loss 6.6339\n",
      "** on validation data loss is 6.5088\n",
      "Time taken for 1 epoch: 32.40 secs\n",
      "\n",
      "Saving checkpoint for epoch 4 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-4\n",
      "Epoch 5 Batch 0 Loss 6.7014\n",
      "Epoch 5 Batch 50 Loss 6.4985\n",
      "Epoch 5 Loss 6.4700\n",
      "** on validation data loss is 6.5057\n",
      "Time taken for 1 epoch: 31.87 secs\n",
      "\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-5\n",
      "Epoch 6 Batch 0 Loss 6.3827\n",
      "Epoch 6 Batch 50 Loss 6.3420\n",
      "Epoch 6 Loss 6.3126\n",
      "** on validation data loss is 6.2429\n",
      "Time taken for 1 epoch: 32.60 secs\n",
      "\n",
      "Saving checkpoint for epoch 6 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-6\n",
      "Epoch 7 Batch 0 Loss 6.2336\n",
      "Epoch 7 Batch 50 Loss 6.1944\n",
      "Epoch 7 Loss 6.1719\n",
      "** on validation data loss is 6.1567\n",
      "Time taken for 1 epoch: 33.18 secs\n",
      "\n",
      "Saving checkpoint for epoch 7 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-7\n",
      "Epoch 8 Batch 0 Loss 6.1606\n",
      "Epoch 8 Batch 50 Loss 6.0919\n",
      "Epoch 8 Loss 6.0774\n",
      "** on validation data loss is 6.0372\n",
      "Time taken for 1 epoch: 32.54 secs\n",
      "\n",
      "Saving checkpoint for epoch 8 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-8\n",
      "Epoch 9 Batch 0 Loss 6.0141\n",
      "Epoch 9 Batch 50 Loss 6.0125\n",
      "Epoch 9 Loss 6.0030\n",
      "** on validation data loss is 6.0240\n",
      "Time taken for 1 epoch: 33.06 secs\n",
      "\n",
      "Saving checkpoint for epoch 9 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-9\n",
      "Epoch 10 Batch 0 Loss 5.9655\n",
      "Epoch 10 Batch 50 Loss 5.9424\n",
      "Epoch 10 Loss 5.9316\n",
      "** on validation data loss is 5.9439\n",
      "Time taken for 1 epoch: 34.09 secs\n",
      "\n",
      "Saving checkpoint for epoch 10 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-10\n",
      "Epoch 11 Batch 0 Loss 5.9862\n",
      "Epoch 11 Batch 50 Loss 5.8836\n",
      "Epoch 11 Loss 5.8748\n",
      "** on validation data loss is 5.8259\n",
      "Time taken for 1 epoch: 34.24 secs\n",
      "\n",
      "Saving checkpoint for epoch 11 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-11\n",
      "Epoch 12 Batch 0 Loss 5.8329\n",
      "Epoch 12 Batch 50 Loss 5.8302\n",
      "Epoch 12 Loss 5.8245\n",
      "** on validation data loss is 5.9670\n",
      "Time taken for 1 epoch: 33.46 secs\n",
      "\n",
      "Saving checkpoint for epoch 12 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-12\n",
      "Epoch 13 Batch 0 Loss 6.0480\n",
      "Epoch 13 Batch 50 Loss 5.7880\n",
      "Epoch 13 Loss 5.7785\n",
      "** on validation data loss is 5.7768\n",
      "Time taken for 1 epoch: 32.91 secs\n",
      "\n",
      "Saving checkpoint for epoch 13 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-13\n",
      "Epoch 14 Batch 0 Loss 5.8164\n",
      "Epoch 14 Batch 50 Loss 5.7361\n",
      "Epoch 14 Loss 5.7328\n",
      "** on validation data loss is 5.7576\n",
      "Time taken for 1 epoch: 32.69 secs\n",
      "\n",
      "Saving checkpoint for epoch 14 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-14\n",
      "Epoch 15 Batch 0 Loss 5.8507\n",
      "Epoch 15 Batch 50 Loss 5.7000\n",
      "Epoch 15 Loss 5.6878\n",
      "** on validation data loss is 5.6459\n",
      "Time taken for 1 epoch: 32.83 secs\n",
      "\n",
      "Saving checkpoint for epoch 15 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-15\n",
      "Epoch 16 Batch 0 Loss 5.7038\n",
      "Epoch 16 Batch 50 Loss 5.6522\n",
      "Epoch 16 Loss 5.6453\n",
      "** on validation data loss is 5.6441\n",
      "Time taken for 1 epoch: 31.82 secs\n",
      "\n",
      "Saving checkpoint for epoch 16 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-16\n",
      "Epoch 17 Batch 0 Loss 5.6434\n",
      "Epoch 17 Batch 50 Loss 5.6210\n",
      "Epoch 17 Loss 5.6109\n",
      "** on validation data loss is 5.6352\n",
      "Time taken for 1 epoch: 32.15 secs\n",
      "\n",
      "Saving checkpoint for epoch 17 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-17\n",
      "Epoch 18 Batch 0 Loss 5.6365\n",
      "Epoch 18 Batch 50 Loss 5.5818\n",
      "Epoch 18 Loss 5.5688\n",
      "** on validation data loss is 5.5688\n",
      "Time taken for 1 epoch: 32.71 secs\n",
      "\n",
      "Saving checkpoint for epoch 18 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-18\n",
      "Epoch 19 Batch 0 Loss 5.6313\n",
      "Epoch 19 Batch 50 Loss 5.5294\n",
      "Epoch 19 Loss 5.5269\n",
      "** on validation data loss is 5.5000\n",
      "Time taken for 1 epoch: 32.89 secs\n",
      "\n",
      "Saving checkpoint for epoch 19 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-19\n",
      "Epoch 20 Batch 0 Loss 5.6545\n",
      "Epoch 20 Batch 50 Loss 5.4874\n",
      "Epoch 20 Loss 5.4802\n",
      "** on validation data loss is 5.4583\n",
      "Time taken for 1 epoch: 32.91 secs\n",
      "\n",
      "Saving checkpoint for epoch 20 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-20\n",
      "Epoch 21 Batch 0 Loss 5.5437\n",
      "Epoch 21 Batch 50 Loss 5.4529\n",
      "Epoch 21 Loss 5.4478\n",
      "** on validation data loss is 5.4349\n",
      "Time taken for 1 epoch: 31.65 secs\n",
      "\n",
      "Saving checkpoint for epoch 21 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-21\n",
      "Epoch 22 Batch 0 Loss 5.4816\n",
      "Epoch 22 Batch 50 Loss 5.4298\n",
      "Epoch 22 Loss 5.4145\n",
      "** on validation data loss is 5.3825\n",
      "Time taken for 1 epoch: 31.48 secs\n",
      "\n",
      "Saving checkpoint for epoch 22 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-22\n",
      "Epoch 23 Batch 0 Loss 5.4413\n",
      "Epoch 23 Batch 50 Loss 5.3953\n",
      "Epoch 23 Loss 5.3853\n",
      "** on validation data loss is 5.4528\n",
      "Time taken for 1 epoch: 31.26 secs\n",
      "\n",
      "Saving checkpoint for epoch 23 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-23\n",
      "Epoch 24 Batch 0 Loss 5.4962\n",
      "Epoch 24 Batch 50 Loss 5.3591\n",
      "Epoch 24 Loss 5.3613\n",
      "** on validation data loss is 5.3815\n",
      "Time taken for 1 epoch: 31.96 secs\n",
      "\n",
      "Saving checkpoint for epoch 24 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-24\n",
      "Epoch 25 Batch 0 Loss 5.4148\n",
      "Epoch 25 Batch 50 Loss 5.3307\n",
      "Epoch 25 Loss 5.3369\n",
      "** on validation data loss is 5.3224\n",
      "Time taken for 1 epoch: 34.28 secs\n",
      "\n",
      "Saving checkpoint for epoch 25 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-25\n",
      "Epoch 26 Batch 0 Loss 5.2802\n",
      "Epoch 26 Batch 50 Loss 5.3185\n",
      "Epoch 26 Loss 5.3176\n",
      "** on validation data loss is 5.3167\n",
      "Time taken for 1 epoch: 34.93 secs\n",
      "\n",
      "Saving checkpoint for epoch 26 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-26\n",
      "Epoch 27 Batch 0 Loss 5.4438\n",
      "Epoch 27 Batch 50 Loss 5.2991\n",
      "Epoch 27 Loss 5.2987\n",
      "** on validation data loss is 5.2837\n",
      "Time taken for 1 epoch: 28.03 secs\n",
      "\n",
      "Saving checkpoint for epoch 27 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-27\n",
      "Epoch 28 Batch 0 Loss 5.1888\n",
      "Epoch 28 Batch 50 Loss 5.2745\n",
      "Epoch 28 Loss 5.2827\n",
      "** on validation data loss is 5.3490\n",
      "Time taken for 1 epoch: 28.40 secs\n",
      "\n",
      "Saving checkpoint for epoch 28 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-28\n",
      "Epoch 29 Batch 0 Loss 5.4786\n",
      "Epoch 29 Batch 50 Loss 5.2651\n",
      "Epoch 29 Loss 5.2664\n",
      "** on validation data loss is 5.2597\n",
      "Time taken for 1 epoch: 29.30 secs\n",
      "\n",
      "Saving checkpoint for epoch 29 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-29\n",
      "Epoch 30 Batch 0 Loss 5.2675\n",
      "Epoch 30 Batch 50 Loss 5.2549\n",
      "Epoch 30 Loss 5.2537\n",
      "** on validation data loss is 5.2734\n",
      "Time taken for 1 epoch: 30.27 secs\n",
      "\n",
      "Saving checkpoint for epoch 30 at ./checkpoints/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64--uk-cond/ckpt-30\n",
      "Epoch 31 Batch 0 Loss 5.3390\n",
      "Epoch 31 Batch 50 Loss 5.2321\n",
      "Epoch 31 Loss 5.2378\n",
      "** on validation data loss is 5.2964\n",
      "Time taken for 1 epoch: 31.32 secs\n",
      "\n",
      "Stopping early, last 2 val losses are: [<tf.Tensor: shape=(), dtype=float32, numpy=5.273408>, <tf.Tensor: shape=(), dtype=float32, numpy=5.296429>]                       \n",
      "Best was 5.260\n",
      "\n",
      "\n",
      "Wrote transformer.results to training_history/v2b__nld_4-dm_128-nh_2-i_2-dr_0__1-opt_adam-lwi_0-bs_64.pickle\n"
     ]
    }
   ],
   "source": [
    "from my_lib.BanksformerGen import Transformer\n",
    "import pickle \n",
    "\n",
    "\n",
    "all_models = []\n",
    "for_df = []\n",
    "\n",
    "\n",
    "def to_num(x):\n",
    "    try: return int(x)\n",
    "    except: return float(x)\n",
    "\n",
    "    \n",
    "def id_str_to_folder(id_str):\n",
    "    return id_str.replace(\".\", \"__\")\n",
    "beta = 1\n",
    "\n",
    "\n",
    "# moredate\n",
    "LOSS_WEIGHTS_OLD = {\n",
    " 'td_sc':1.,\n",
    " 'year': 0.5,\n",
    " 'month': 0.15,\n",
    " 'day': 0.25,\n",
    " 'dow': 0.1,\n",
    " 'tcode_num': 1.,\n",
    " 'log_amount_sc': 2.}\n",
    "\n",
    "\n",
    "LOSS_WEIGHTS_0 = {\n",
    " 'td_sc':1.,\n",
    " 'month': 0.015,\n",
    " 'day': 0.025,\n",
    " 'dow': 0.01,\n",
    " 'tcode_num': 1.,\n",
    " 'log_amount_sc': 2.}\n",
    "\n",
    "\n",
    "\n",
    "LOSS_WEIGHTS_MID = {\n",
    " 'td_sc':1.,\n",
    " 'month': 0.07,\n",
    " 'day': 0.1,\n",
    " 'dow': 0.04,\n",
    " 'tcode_num': 1.,\n",
    " 'log_amount_sc': 2.}\n",
    "\n",
    "\n",
    "\n",
    "lws = [(LOSS_WEIGHTS_0, \"0\"), (LOSS_WEIGHTS_OLD, \"moredate\")]\n",
    "\n",
    "# lws = [(LOSS_WEIGHTS_MID, \"mid\")]\n",
    "\n",
    "td_loss_fns = [(loss_mse, \"loss_mse\")]\n",
    "\n",
    "\n",
    "EPOCHS = 80\n",
    "EARLY_STOP = 2\n",
    "\n",
    "num_layers_enc = None\n",
    "dropout_rate = 0.1\n",
    "dr = dropout_rate\n",
    "opt_name = \"adam\"\n",
    "# td_loss_fn = loss_mse\n",
    "\n",
    "\n",
    "## Tuning these ! \n",
    "d_model = 128\n",
    "num_layers_dec = 4\n",
    "num_heads = 2\n",
    "bs = 64\n",
    "# lws # above\n",
    "\n",
    "\n",
    "LOSS_WEIGHTS, lwi = lws[0]\n",
    "\n",
    "\n",
    "dff = d_model\n",
    "\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "\n",
    "                print(datetime.datetime.now().strftime(\"%H:%M\"))\n",
    "\n",
    "\n",
    "                transformer = Transformer(\n",
    "                    num_layers_enc=num_layers_enc, num_layers_dec=num_layers_dec,\n",
    "                    d_model=d_model,\n",
    "                    num_heads=num_heads,\n",
    "                    dff=dff,\n",
    "                    maximum_position_encoding=256,\n",
    "                   net_info = None, \n",
    "                    inp_dim = n_feat_inp,\n",
    "                    final_dim= None,\n",
    "                    config=config,\n",
    "                    rate=dr)\n",
    "\n",
    "                optimizer = tf.keras.optimizers.Adam()\n",
    "                transformer.optimizer =  optimizer\n",
    "\n",
    "\n",
    "                train_batches = make_batches(ds_tr, BUFFER_SIZE, bs)\n",
    "\n",
    "\n",
    "                transformer.loss_function = loss_function\n",
    "                LOSS_WEIGHTS[\"dtme\"] = LOSS_WEIGHTS[\"day\"]\n",
    "\n",
    "                LOSS_WEIGHTS[\"k_symbol_num\"] = LOSS_WEIGHTS[\"tcode_num\"]\n",
    "                LOSS_WEIGHTS[\"operation_num\"] = LOSS_WEIGHTS[\"tcode_num\"]\n",
    "                LOSS_WEIGHTS[\"type_num\"] = LOSS_WEIGHTS[\"tcode_num\"]\n",
    "                transformer.LOSS_WEIGHTS = LOSS_WEIGHTS\n",
    "\n",
    "                id_str = f\"v2b__nld_{num_layers_dec}-dm_{d_model}-nh_{num_heads}-i_{i}-dr_{dr}-opt_{opt_name}-lwi_{lwi}-bs_{bs}\"\n",
    "\n",
    "                print(\"Begin running\", id_str)\n",
    "                transformer.id_str = id_str\n",
    "\n",
    "\n",
    "                all_models.append(transformer)\n",
    "                transformer.compile()\n",
    "\n",
    "\n",
    "                transformer.checkpoint_path = f\"./checkpoints/{id_str_to_folder(transformer.id_str)}-{ds_suffix}-{nb_id}\"\n",
    "                transformer.ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                                           optimizer=optimizer)\n",
    "                transformer.ckpt_manager = tf.train.CheckpointManager(transformer.ckpt, \n",
    "                                                                      transformer.checkpoint_path, max_to_keep=EARLY_STOP)\n",
    "\n",
    "                if transformer.ckpt_manager.latest_checkpoint:\n",
    "                    transformer.ckpt.restore(transformer.ckpt_manager.latest_checkpoint)\n",
    "                    print('Latest checkpoint restored!!')    \n",
    "                    continue\n",
    "\n",
    "\n",
    "                transformer.fit(train_batches, x_cv, targ_cv, epochs= EPOCHS, early_stop=EARLY_STOP, print_every=50, ckpt_every = 1)\n",
    "\n",
    "                transformer.fit_time = time.time() - start\n",
    "                transformer.results[\"fit_time\"] = transformer.fit_time \n",
    "\n",
    "                with open(f\"training_history/{id_str_to_folder(transformer.id_str)}.pickle\", \"wb\") as f:\n",
    "                    pickle.dump(transformer.results, f) \n",
    "                    print(\"Wrote transformer.results to\", f.name)\n",
    "\n",
    "\n",
    "                for_df.append((num_layers_dec, d_model, num_heads, i, dr, beta, dff,\n",
    "                               np.min(transformer.results[\"val_loss\"]), opt_name, transformer.id_str))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(for_df, columns=['num_layers_dec', 'd_model', 'num_heads', 'i', \"dr\", \"beta\", \"dff\",\n",
    "                                                \"val loss\", \"opt name\",\"id_str\"]).sort_values(\"val loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_layers_dec</th>\n",
       "      <th>d_model</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>i</th>\n",
       "      <th>dr</th>\n",
       "      <th>beta</th>\n",
       "      <th>dff</th>\n",
       "      <th>val loss</th>\n",
       "      <th>opt name</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>5.259680</td>\n",
       "      <td>adam</td>\n",
       "      <td>v2b__nld_4-dm_128-nh_2-i_2-dr_0.1-opt_adam-lwi_0-bs_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>5.291912</td>\n",
       "      <td>adam</td>\n",
       "      <td>v2b__nld_4-dm_128-nh_2-i_0-dr_0.1-opt_adam-lwi_0-bs_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>5.424337</td>\n",
       "      <td>adam</td>\n",
       "      <td>v2b__nld_4-dm_128-nh_2-i_1-dr_0.1-opt_adam-lwi_0-bs_64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_layers_dec  d_model  num_heads  i   dr  beta  dff  val loss opt name  \\\n",
       "2               4      128          2  2  0.1     1  128  5.259680     adam   \n",
       "0               4      128          2  0  0.1     1  128  5.291912     adam   \n",
       "1               4      128          2  1  0.1     1  128  5.424337     adam   \n",
       "\n",
       "                                                   id_str  \n",
       "2  v2b__nld_4-dm_128-nh_2-i_2-dr_0.1-opt_adam-lwi_0-bs_64  \n",
       "0  v2b__nld_4-dm_128-nh_2-i_0-dr_0.1-opt_adam-lwi_0-bs_64  \n",
       "1  v2b__nld_4-dm_128-nh_2-i_1-dr_0.1-opt_adam-lwi_0-bs_64  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', None, \"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    display(df.sort_values(\"val loss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = all_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdc61c38130>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(transformer.results[\"val_loss\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate  \n",
    "Warning: Code below is not nice and should be refactored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_YEARS_SPAN = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running clocks[7] = np.array([encode_time_value(val, 7) for val in range(7)])\n",
      "Running clocks[31] = np.array([encode_time_value(val, 31) for val in range(31)])\n",
      "Running clocks[12] = np.array([encode_time_value(val, 12) for val in range(12)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys([7, 31, 12])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from my_lib.encoding import encode_time_value\n",
    "#, decode_time_value\n",
    "\n",
    "clocks = {}\n",
    "for max_val in [7, 31, 12]:\n",
    "    cmd = f\"clocks[{max_val}] = np.array([encode_time_value(val, {max_val}) for val in range({max_val})])\"\n",
    "    print(\"Running\", cmd)\n",
    "    exec(cmd)\n",
    "    \n",
    "clocks.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = data_encoder.START_DATE \n",
    "START_DATE = data_encoder.START_DATE.split()[0]\n",
    "\n",
    "import calendar\n",
    "get_dtme = lambda d: calendar.monthrange(d.year, d.month)[1] - d.day\n",
    "\n",
    "if type(START_DATE) == str:\n",
    "    START_DATE = datetime.datetime.strptime(START_DATE, \"%Y-%m-%d\").date()\n",
    "    \n",
    "    \n",
    "\n",
    "END_DATE = START_DATE.replace(year = START_DATE.year+ MAX_YEARS_SPAN)\n",
    "\n",
    "ALL_DATES = [START_DATE + datetime.timedelta(i) for i in range((END_DATE - START_DATE).days)]\n",
    "\n",
    "# AD = np.array([(d.month % 12, d.day % 31, d.weekday() % 7, i, d.year) for i, d in enumerate(ALL_DATES)])\n",
    "AD = np.array([(d.month % 12, d.day % 31, d.weekday() % 7, i, d.year, get_dtme(d)) for i, d in enumerate(ALL_DATES)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_lib.transformer_core import create_masks\n",
    "\n",
    "    \n",
    "def reencode_net_prediction(net_name, predictions):\n",
    "    \n",
    "    date_info = {'month':12, 'day':31, 'dtme':31, 'dow':7}\n",
    "    batch_size = predictions.shape[0]\n",
    "    \n",
    "\n",
    "    if net_name in ['balance', 'td_sc', 'dss', \"log_amount_sc\"]:\n",
    "        return predictions[:, :, 0:1]\n",
    "\n",
    "\n",
    "    elif net_name in date_info.keys():\n",
    "        dim = FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)\n",
    "\n",
    "        \n",
    "        choosen =  np.array([np.random.choice(choices, p=p) for p in ps])\n",
    "        \n",
    "        x = bulk_encode_time_value(choosen, max_val=dim)\n",
    "        \n",
    "        return np.reshape(x, newshape=(batch_size, -1, 2))\n",
    "\n",
    "    \n",
    "    elif \"_num\" in net_name:\n",
    "        dim = FIELD_DIMS_NET[net_name]\n",
    "        choices = np.arange(dim)\n",
    "\n",
    "        ps = tf.nn.softmax(predictions, axis=2).numpy().reshape(-1, dim)\n",
    "        \n",
    "\n",
    "        \n",
    "        choosen =  np.reshape([np.random.choice(choices, p=p) for p in ps], newshape=(batch_size, -1))\n",
    "        \n",
    "\n",
    "        return tf.one_hot(choosen, depth=dim)\n",
    "    \n",
    "    else:\n",
    "        raise Exception(f\"Got invalid net_name: {net_name}\")\n",
    "\n",
    "days_per_month = np.array([(datetime.date(1990, month, 1) - datetime.timedelta(1)).day for month in range(1,13)]) # 0 = dec\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def get_short_name(tcode):\n",
    "    return short_names[tcode]\n",
    "\n",
    "\n",
    "@np.vectorize\n",
    "def get_date_str(mm, dd):\n",
    "    return f\"{mm:02d}/{dd:02d}\"\n",
    "\n",
    "\n",
    "def bulk_decode(seqs, start_dates, return_single_df=False, return_df_list=False):\n",
    "    \n",
    "\n",
    "    ages = seqs[:, 0, :] * data_encoder.ATTR_SCALE\n",
    "    seqs = seqs[:, 1:, :]\n",
    "    assert np.sum(np.diff(ages)) == 0, f\"Bad formating, expected all entries same in each row, got {ages}\"\n",
    "\n",
    "    \n",
    "    amts = seqs[:, :, FIELD_STARTS_IN[\"log_amount_sc\"]].numpy() * data_encoder.LOG_AMOUNT_SCALE\n",
    "    amts = 10 ** amts\n",
    "    amts = np.round(amts - 1.0, 2)\n",
    "\n",
    "\n",
    "    days_passed = np.round(seqs[:, :, FIELD_STARTS_IN[\"td_sc\"]] *data_encoder.TD_SCALE ).astype(int)\n",
    "  \n",
    "\n",
    "\n",
    "    months = np.argmax(seqs[:, :, FIELD_STARTS_IN[\"month\"]: FIELD_STARTS_IN[\"month\"] + FIELD_DIMS_IN[\"month\"]], axis=-1)\n",
    "    \n",
    "    \n",
    "    days = np.argmax(seqs[:, :, FIELD_STARTS_IN[\"day\"]: FIELD_STARTS_IN[\"day\"] + FIELD_DIMS_IN[\"day\"]], axis=-1)\n",
    "    days[days==0] = days_per_month[months[days==0]]\n",
    "    months[months==0] = 12 # needs to be done after days (above)\n",
    "    date_fields = get_date_str(months, days)\n",
    "    \n",
    "    dpc = np.cumsum(days_passed, axis=1) \n",
    "    dates = np.array([[start_dates[i] + datetime.timedelta(int(d)) for d in dpc[i]]for i in range(len(start_dates))])\n",
    "    \n",
    "    \n",
    "    code_names = []\n",
    "    code_vals = []\n",
    "    for field, start_i in FIELD_STARTS_IN.items():\n",
    "        if \"_num\" in field:\n",
    "            code_names.append(field)\n",
    "            code_vals.append(np.argmax(seqs[:, :, start_i: start_i + FIELD_DIMS_IN[field]], axis=-1))\n",
    "        \n",
    "\n",
    "    ages = np.repeat(ages[:, 0:1], amts.shape[1], axis=1).astype(int)\n",
    "    \n",
    "\n",
    "    return_vals = amts, *code_vals, date_fields, days_passed, ages, dates\n",
    "    return_lbls = \"amount\", *code_names, \"date_fields\", \"days_passed\", \"age\", \"date\"\n",
    "\n",
    "    \n",
    "    if return_df_list:\n",
    "        return [pd.DataFrame.from_records(zip(*x), columns=return_lbls) for x in zip(*return_vals)]\n",
    "    \n",
    "    if return_single_df:\n",
    "        return pd.DataFrame.from_records([x for x in zip(*[x.reshape(-1) for x in return_vals])], columns=return_lbls)\n",
    "    \n",
    "    return return_vals\n",
    "\n",
    "\n",
    "\n",
    "def nearest_clock_ind(enc, max_val):\n",
    "    clock = clocks[max_val]\n",
    "    diffs = clock - enc\n",
    "    d_sq =  np.sum(diffs**2, axis=1)\n",
    "    return np.argmin(d_sq)\n",
    "\n",
    "\n",
    "def nearest_clock_enc(enc, max_val):\n",
    "    clock = clocks[max_val]\n",
    "    diffs = clock - enc\n",
    "    d_sq =  np.sum(diffs**2, axis=1)\n",
    "    return clock[np.argmin(d_sq)]\n",
    "\n",
    "\n",
    "def bulk_nearest_clock_ind(encs, max_val):\n",
    "    batch_size = encs.shape[0]\n",
    "    inds =  np.array([nearest_clock_ind(enc, max_val) \n",
    "                      for enc in tf.reshape(encs, shape=(-1, 2))])\n",
    "    return inds.reshape((batch_size, -1))\n",
    "\n",
    "\n",
    "def bulk_nearest_clock_enc(encs, max_val):\n",
    "    print(\"Encs shape\", encs.shape)\n",
    "\n",
    "    batch_size = encs.shape[0]\n",
    "    new_encs =  np.array([nearest_clock_enc(enc, max_val) \n",
    "                      for enc in tf.reshape(encs, shape=(-1, encs.shape[-1]))])\n",
    "    \n",
    "    print(\"new_Encs shape\", new_encs.shape)\n",
    "    \n",
    "    return new_encs.reshape((batch_size, -1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seqs(length, ages, start_dates, greedy_dates = False, return_single_df=False, return_df_list=False):\n",
    "    \n",
    "    if return_single_df and return_df_list:\n",
    "        raise Exception(\"At most one of: 'return_single_df' and 'return_df_list' can be true\")\n",
    "    \n",
    "    date_inds = np.array([(d - START_DATE).days for d in start_dates])\n",
    "    \n",
    "    max_length = length\n",
    "\n",
    "    output = np.repeat(np.array(ages)[:, None, None], repeats=n_feat_inp, axis=2) / data_encoder.ATTR_SCALE\n",
    "    \n",
    "    raw_preds = []\n",
    "    raw_preds.append(output)\n",
    "\n",
    "    date_info = None\n",
    "    \n",
    "    \n",
    "    for i in range(max_length):\n",
    "\n",
    "\n",
    "        combined_mask, dec_padding_mask = create_masks(output)\n",
    "\n",
    "\n",
    "        predictions, attn, raw_ps, date_inds, enc_preds, date_info = call_to_generate(transformer, output, \n",
    "                                                 True, \n",
    "                                                 combined_mask, \n",
    "                                                 dec_padding_mask, date_inds, date_info, greedy_dates =greedy_dates)\n",
    "\n",
    "        \n",
    "        raw_preds.append(raw_ps)\n",
    "\n",
    "        enc_preds = tf.reshape(tf.constant(enc_preds), shape=(-1,1, n_feat_inp))\n",
    "\n",
    "        output = tf.concat([output, enc_preds], axis=1)\n",
    "\n",
    "        \n",
    "    return bulk_decode(output, start_dates, return_single_df, return_df_list), output, raw_preds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Forward pass through transformer\n",
    "# \n",
    "# Returns: preds, attn_w, raw_preds, inds\n",
    "# the returned preds have multiple timesteps, but we only \n",
    "# care about the last (it's the only new one)\n",
    "def call_to_generate(transformer, tar, training,\n",
    "           look_ahead_mask, dec_padding_mask, start_inds, prev_date_info=None, greedy_dates = True):\n",
    "    \n",
    "\n",
    "    ### Pass through decoder stack ###\n",
    "    dec_output, attention_weights = transformer.decoder(\n",
    "        tar, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "\n",
    "    final_output = transformer.final_layer(dec_output) \n",
    "\n",
    "    \n",
    "    \n",
    "    ### Predict each field  ###\n",
    "    preds = {}\n",
    "    raw_preds = {}\n",
    "    encoded_preds_d = {}\n",
    "    encoded_preds = []\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    for net_name in transformer.ORDER:  \n",
    "        pred = transformer.__getattribute__(net_name)(final_output)\n",
    "        raw_preds[net_name] = pred\n",
    "        \n",
    "        pred = reencode_net_prediction(net_name, pred) # keeps time step\n",
    "        preds[net_name] = pred\n",
    "        \n",
    "        encoded_preds_d[net_name] = pred[:,-1,:] \n",
    "        encoded_preds.append(pred[:,-1,:])\n",
    "        final_output = tf.concat([final_output, pred], axis=2)\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    pred_date = None\n",
    "    \n",
    "\n",
    "    combined_date_info, inds = raw_dates_to_reencoded(raw_preds, start_inds)\n",
    "    \n",
    "    encoded_preds_d.update(combined_date_info)\n",
    "    \n",
    "    l = [encoded_preds_d[k] for k in transformer.ORDER]\n",
    "    encoded_preds =  tf.expand_dims(tf.concat(l, axis=1), axis=1)\n",
    "    \n",
    "\n",
    "    return preds, attention_weights, raw_preds, start_inds + inds, encoded_preds, pred_date\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes raw predictions (info about predicted day, month, dow, and days passed) and start inds \n",
    "# (indicate the current date for each of the seqs) \n",
    "# Computes a number of days passed for each based on inputs (either greedily or with sampling)\n",
    "# returns the new_dates (old_dates + days passed) and their indicies\n",
    "def raw_dates_to_reencoded(raw, start_inds,  max_days = 100, greedy_decode=False):\n",
    "    \n",
    "\n",
    "    all_ps = [tf.nn.softmax(raw[k][:,-1]).numpy() for k in [\"month\", \"day\", \"dow\", \"dtme\"]]\n",
    "\n",
    "    timesteps = np.zeros(len(start_inds)).astype(int)\n",
    "\n",
    "    sc = data_encoder.TD_SCALE\n",
    "    for i, (month_ps, day_ps, dow_ps, dtme_ps, td_pred, si) in enumerate(zip(*all_ps, raw[\"td_sc\"][:,-1].numpy(), start_inds)):\n",
    "        \n",
    "        \n",
    "\n",
    "        ps = month_ps[AD[si:si+max_days,0]]*day_ps[AD[si:si+max_days,1]]*dow_ps[AD[si:si+max_days,2]] *dtme_ps[AD[si:si+max_days,-1]] * \\\n",
    "                np.exp(log_normal_pdf_gen(AD[si:si+max_days,3]-si, mean = td_pred[0]*sc, logvar=td_pred[1]*sc))\n",
    "\n",
    "\n",
    "        \n",
    "        if greedy_decode:\n",
    "            timesteps[i] = np.argmax(ps)\n",
    "        else:\n",
    "            timesteps[i] = np.random.choice(max_days, p=ps/sum(ps))\n",
    "        \n",
    "        \n",
    "    inds = start_inds + timesteps\n",
    "    \n",
    "    \n",
    "    return_ = {}\n",
    "    return_[\"td_sc\"] = tf.expand_dims(timesteps.astype(np.float32)/ data_encoder.TD_SCALE, axis=1)\n",
    "    return_[\"month\"] = bulk_encode_time_value(AD[inds, 0], 12)\n",
    "    return_[\"day\"] = bulk_encode_time_value(AD[inds, 1], 31)\n",
    "    return_[\"dow\"] = bulk_encode_time_value(AD[inds, 2], 7)\n",
    "    return_[\"dtme\"] = bulk_encode_time_value(AD[inds, -1], 31)\n",
    "    \n",
    "    \n",
    "\n",
    "    return return_, timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs_dfs, seqs, raw = generate_seqs(length= 25, \n",
    "                          ages=[75, 25], \n",
    "                          start_dates=[START_DATE, START_DATE+datetime.timedelta(days=1)], \n",
    "                          greedy_dates=False,\n",
    "                          return_df_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>tcode_num</th>\n",
       "      <th>date_fields</th>\n",
       "      <th>days_passed</th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.369995</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.619999</td>\n",
       "      <td>16</td>\n",
       "      <td>12/01</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1055.949951</td>\n",
       "      <td>17</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.530001</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.860001</td>\n",
       "      <td>28</td>\n",
       "      <td>12/01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.150002</td>\n",
       "      <td>22</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.839996</td>\n",
       "      <td>7</td>\n",
       "      <td>12/01</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>167.889999</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>581.109985</td>\n",
       "      <td>34</td>\n",
       "      <td>12/31</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.430000</td>\n",
       "      <td>33</td>\n",
       "      <td>12/31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>504.390015</td>\n",
       "      <td>34</td>\n",
       "      <td>12/31</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.279999</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.580002</td>\n",
       "      <td>0</td>\n",
       "      <td>12/01</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>698.960022</td>\n",
       "      <td>34</td>\n",
       "      <td>12/01</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35.580002</td>\n",
       "      <td>36</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.360001</td>\n",
       "      <td>3</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1035.589966</td>\n",
       "      <td>5</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>199.149994</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.740000</td>\n",
       "      <td>40</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.690001</td>\n",
       "      <td>8</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>194.970001</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26.740000</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.850000</td>\n",
       "      <td>4</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>54.669998</td>\n",
       "      <td>10</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29.650000</td>\n",
       "      <td>16</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount  tcode_num date_fields  days_passed  age        date\n",
       "0    197.369995          2       12/01           18   25  2017-04-20\n",
       "1     39.619999         16       12/01            4   25  2017-04-24\n",
       "2   1055.949951         17       12/01            0   25  2017-04-24\n",
       "3     23.530001         31       12/01            0   25  2017-04-24\n",
       "4     40.860001         28       12/01            3   25  2017-04-27\n",
       "5     35.150002         22       12/01            0   25  2017-04-27\n",
       "6     65.839996          7       12/01            1   25  2017-04-28\n",
       "7    167.889999          2       12/01            3   25  2017-05-01\n",
       "8    581.109985         34       12/31            4   25  2017-05-05\n",
       "9     10.430000         33       12/31            6   25  2017-05-11\n",
       "10   504.390015         34       12/31            7   25  2017-05-18\n",
       "11    35.279999         31       12/01            4   25  2017-05-22\n",
       "12    51.580002          0       12/01            1   25  2017-05-23\n",
       "13   698.960022         34       12/01            2   25  2017-05-25\n",
       "14    35.580002         36       12/01            0   25  2017-05-25\n",
       "15    33.360001          3       12/01            0   25  2017-05-25\n",
       "16  1035.589966          5       12/01            0   25  2017-05-25\n",
       "17   199.149994          2       12/01            0   25  2017-05-25\n",
       "18     8.740000         40       12/01            0   25  2017-05-25\n",
       "19    19.690001          8       12/01            0   25  2017-05-25\n",
       "20   194.970001          2       12/01            0   25  2017-05-25\n",
       "21    26.740000         31       12/01            0   25  2017-05-25\n",
       "22     6.850000          4       12/01            0   25  2017-05-25\n",
       "23    54.669998         10       12/01            0   25  2017-05-25\n",
       "24    29.650000         16       12/01            0   25  2017-05-25"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = seqs_dfs[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_num(self, field, code):\n",
    "    field = field.replace(\"_num\", \"\")\n",
    "    d = self.__getattribute__(f\"{field}_to_num\".upper())\n",
    "    return d[code]\n",
    "\n",
    "\n",
    "\n",
    "def get_code_from_num(self, field, num):\n",
    "    field = field.replace(\"_num\", \"\")\n",
    "    d = self.__getattribute__(f\"num_to_{field}\".upper())\n",
    "    return d[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from field_config import CAT_FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>tcode_num</th>\n",
       "      <th>date_fields</th>\n",
       "      <th>days_passed</th>\n",
       "      <th>age</th>\n",
       "      <th>date</th>\n",
       "      <th>tcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.369995</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>Credit Card Payment__Credit Card__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.619999</td>\n",
       "      <td>16</td>\n",
       "      <td>12/01</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>O2 Mobile__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1055.949951</td>\n",
       "      <td>17</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>Mortgage__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.530001</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-24</td>\n",
       "      <td>Tipple Box__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.860001</td>\n",
       "      <td>28</td>\n",
       "      <td>12/01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>BT Broadband__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.150002</td>\n",
       "      <td>22</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>BT Mobile__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65.839996</td>\n",
       "      <td>7</td>\n",
       "      <td>12/01</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-04-28</td>\n",
       "      <td>TalkTalk Broadband__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>167.889999</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>Credit Card Payment__Credit Card__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>581.109985</td>\n",
       "      <td>34</td>\n",
       "      <td>12/31</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>Weekly__Income__Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.430000</td>\n",
       "      <td>33</td>\n",
       "      <td>12/31</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>Now TV__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>504.390015</td>\n",
       "      <td>34</td>\n",
       "      <td>12/31</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>Weekly__Income__Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>35.279999</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>Tipple Box__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>51.580002</td>\n",
       "      <td>0</td>\n",
       "      <td>12/01</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>Energy__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>698.960022</td>\n",
       "      <td>34</td>\n",
       "      <td>12/01</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Weekly__Income__Credit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>35.580002</td>\n",
       "      <td>36</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Virgin Mobile Mobile__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33.360001</td>\n",
       "      <td>3</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Water Bill__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1035.589966</td>\n",
       "      <td>5</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Rent__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>199.149994</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Credit Card Payment__Credit Card__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.740000</td>\n",
       "      <td>40</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Pact Coffee__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.690001</td>\n",
       "      <td>8</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Groceries - Food &amp; Drinks__Card Transaction__D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>194.970001</td>\n",
       "      <td>2</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Credit Card Payment__Credit Card__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26.740000</td>\n",
       "      <td>31</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Tipple Box__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.850000</td>\n",
       "      <td>4</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Amazon Prime__Subscription__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>54.669998</td>\n",
       "      <td>10</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Gas Station - Car Fuel__Card Transaction__Debit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>29.650000</td>\n",
       "      <td>16</td>\n",
       "      <td>12/01</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>O2 Mobile__Utility Bill__Debit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         amount  tcode_num date_fields  days_passed  age        date  \\\n",
       "0    197.369995          2       12/01           18   25  2017-04-20   \n",
       "1     39.619999         16       12/01            4   25  2017-04-24   \n",
       "2   1055.949951         17       12/01            0   25  2017-04-24   \n",
       "3     23.530001         31       12/01            0   25  2017-04-24   \n",
       "4     40.860001         28       12/01            3   25  2017-04-27   \n",
       "5     35.150002         22       12/01            0   25  2017-04-27   \n",
       "6     65.839996          7       12/01            1   25  2017-04-28   \n",
       "7    167.889999          2       12/01            3   25  2017-05-01   \n",
       "8    581.109985         34       12/31            4   25  2017-05-05   \n",
       "9     10.430000         33       12/31            6   25  2017-05-11   \n",
       "10   504.390015         34       12/31            7   25  2017-05-18   \n",
       "11    35.279999         31       12/01            4   25  2017-05-22   \n",
       "12    51.580002          0       12/01            1   25  2017-05-23   \n",
       "13   698.960022         34       12/01            2   25  2017-05-25   \n",
       "14    35.580002         36       12/01            0   25  2017-05-25   \n",
       "15    33.360001          3       12/01            0   25  2017-05-25   \n",
       "16  1035.589966          5       12/01            0   25  2017-05-25   \n",
       "17   199.149994          2       12/01            0   25  2017-05-25   \n",
       "18     8.740000         40       12/01            0   25  2017-05-25   \n",
       "19    19.690001          8       12/01            0   25  2017-05-25   \n",
       "20   194.970001          2       12/01            0   25  2017-05-25   \n",
       "21    26.740000         31       12/01            0   25  2017-05-25   \n",
       "22     6.850000          4       12/01            0   25  2017-05-25   \n",
       "23    54.669998         10       12/01            0   25  2017-05-25   \n",
       "24    29.650000         16       12/01            0   25  2017-05-25   \n",
       "\n",
       "                                                tcode  \n",
       "0             Credit Card Payment__Credit Card__Debit  \n",
       "1                      O2 Mobile__Utility Bill__Debit  \n",
       "2                       Mortgage__Utility Bill__Debit  \n",
       "3                     Tipple Box__Subscription__Debit  \n",
       "4                   BT Broadband__Utility Bill__Debit  \n",
       "5                      BT Mobile__Utility Bill__Debit  \n",
       "6             TalkTalk Broadband__Utility Bill__Debit  \n",
       "7             Credit Card Payment__Credit Card__Debit  \n",
       "8                              Weekly__Income__Credit  \n",
       "9                         Now TV__Subscription__Debit  \n",
       "10                             Weekly__Income__Credit  \n",
       "11                    Tipple Box__Subscription__Debit  \n",
       "12                        Energy__Utility Bill__Debit  \n",
       "13                             Weekly__Income__Credit  \n",
       "14          Virgin Mobile Mobile__Utility Bill__Debit  \n",
       "15                    Water Bill__Utility Bill__Debit  \n",
       "16                          Rent__Utility Bill__Debit  \n",
       "17            Credit Card Payment__Credit Card__Debit  \n",
       "18                   Pact Coffee__Subscription__Debit  \n",
       "19  Groceries - Food & Drinks__Card Transaction__D...  \n",
       "20            Credit Card Payment__Credit Card__Debit  \n",
       "21                    Tipple Box__Subscription__Debit  \n",
       "22                  Amazon Prime__Subscription__Debit  \n",
       "23    Gas Station - Car Fuel__Card Transaction__Debit  \n",
       "24                     O2 Mobile__Utility Bill__Debit  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = \"k_symbol\"\n",
    "for field in CAT_FIELDS:\n",
    "    field = field.replace(\"_num\", \"\")\n",
    "    df[field] = df[field + \"_num\"].apply(lambda x: get_code_from_num(data_encoder, field, x))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "n_seqs_to_generate = len(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>account_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>balance</th>\n",
       "      <th>date</th>\n",
       "      <th>description</th>\n",
       "      <th>flag</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>age</th>\n",
       "      <th>datetime</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dow</th>\n",
       "      <th>year</th>\n",
       "      <th>dtme</th>\n",
       "      <th>tcode</th>\n",
       "      <th>td</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28979</td>\n",
       "      <td>0</td>\n",
       "      <td>0014d0ef29aa9f93</td>\n",
       "      <td>-45.66</td>\n",
       "      <td>228.34</td>\n",
       "      <td>2017-04-24 11:00:00.000000</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Utility Bill</td>\n",
       "      <td>38a21d894127b49d</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-04-24 11:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Energy__Utility Bill__Debit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30006</td>\n",
       "      <td>1</td>\n",
       "      <td>0014d0ef29aa9f93</td>\n",
       "      <td>2842.27</td>\n",
       "      <td>3070.61</td>\n",
       "      <td>2017-04-24 17:36:55.000000</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Income</td>\n",
       "      <td>3941e50e4613a49a</td>\n",
       "      <td>Credit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-04-24 17:36:55</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Monthly__Income__Credit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32220</td>\n",
       "      <td>2</td>\n",
       "      <td>0014d0ef29aa9f93</td>\n",
       "      <td>-167.25</td>\n",
       "      <td>2903.36</td>\n",
       "      <td>2017-04-25 16:00:00.000000</td>\n",
       "      <td>Credit Card Payment</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>c09e8105dcfc85b7</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-04-25 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>Credit Card Payment__Credit Card__Debit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35526</td>\n",
       "      <td>3</td>\n",
       "      <td>0014d0ef29aa9f93</td>\n",
       "      <td>-40.58</td>\n",
       "      <td>2862.78</td>\n",
       "      <td>2017-04-27 16:00:00.000000</td>\n",
       "      <td>Water Bill</td>\n",
       "      <td>Utility Bill</td>\n",
       "      <td>81e4ffc8df86920e</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-04-27 16:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>3</td>\n",
       "      <td>Water Bill__Utility Bill__Debit</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94259</td>\n",
       "      <td>4</td>\n",
       "      <td>0014d0ef29aa9f93</td>\n",
       "      <td>-43.16</td>\n",
       "      <td>2819.62</td>\n",
       "      <td>2017-05-23 17:00:00.000000</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Utility Bill</td>\n",
       "      <td>c0ddd8f8a923d40f</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-23 17:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>Energy__Utility Bill__Debit</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>89757</td>\n",
       "      <td>23</td>\n",
       "      <td>ffd5620bcbf69023</td>\n",
       "      <td>-34.82</td>\n",
       "      <td>2107.16</td>\n",
       "      <td>2017-05-20 15:50:57.000000</td>\n",
       "      <td>Shopping - Household Goods</td>\n",
       "      <td>Card Transaction</td>\n",
       "      <td>908ac96c72f6c3b7</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-20 15:50:57</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>Shopping - Household Goods__Card Transaction__...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>91385</td>\n",
       "      <td>24</td>\n",
       "      <td>ffd5620bcbf69023</td>\n",
       "      <td>-36.50</td>\n",
       "      <td>2070.66</td>\n",
       "      <td>2017-05-22 08:00:00.000000</td>\n",
       "      <td>Water Bill</td>\n",
       "      <td>Utility Bill</td>\n",
       "      <td>66d16692309a0738</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-22 08:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>Water Bill__Utility Bill__Debit</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>91449</td>\n",
       "      <td>25</td>\n",
       "      <td>ffd5620bcbf69023</td>\n",
       "      <td>-38.13</td>\n",
       "      <td>2032.53</td>\n",
       "      <td>2017-05-22 09:00:00</td>\n",
       "      <td>Energy</td>\n",
       "      <td>Utility Bill</td>\n",
       "      <td>b71e06b7164af1e3</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-22 09:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>Energy__Utility Bill__Debit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>93444</td>\n",
       "      <td>26</td>\n",
       "      <td>ffd5620bcbf69023</td>\n",
       "      <td>-42.59</td>\n",
       "      <td>1989.94</td>\n",
       "      <td>2017-05-22 20:47:15</td>\n",
       "      <td>Bar/Pub</td>\n",
       "      <td>Card Transaction</td>\n",
       "      <td>8a28f7eeff2dbabb</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-22 20:47:15</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>Bar/Pub__Card Transaction__Debit</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99790</td>\n",
       "      <td>27</td>\n",
       "      <td>ffd5620bcbf69023</td>\n",
       "      <td>-8.10</td>\n",
       "      <td>1981.84</td>\n",
       "      <td>2017-05-25 19:43:35</td>\n",
       "      <td>Groceries - Food &amp; Drinks</td>\n",
       "      <td>Card Transaction</td>\n",
       "      <td>cf50bb5dcb3d3d32</td>\n",
       "      <td>Debit</td>\n",
       "      <td>-1</td>\n",
       "      <td>2017-05-25 19:43:35</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>Groceries - Food &amp; Drinks__Card Transaction__D...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unnamed: 0  index        account_id   amount  balance  \\\n",
       "0           28979      0  0014d0ef29aa9f93   -45.66   228.34   \n",
       "1           30006      1  0014d0ef29aa9f93  2842.27  3070.61   \n",
       "2           32220      2  0014d0ef29aa9f93  -167.25  2903.36   \n",
       "3           35526      3  0014d0ef29aa9f93   -40.58  2862.78   \n",
       "4           94259      4  0014d0ef29aa9f93   -43.16  2819.62   \n",
       "...           ...    ...               ...      ...      ...   \n",
       "99995       89757     23  ffd5620bcbf69023   -34.82  2107.16   \n",
       "99996       91385     24  ffd5620bcbf69023   -36.50  2070.66   \n",
       "99997       91449     25  ffd5620bcbf69023   -38.13  2032.53   \n",
       "99998       93444     26  ffd5620bcbf69023   -42.59  1989.94   \n",
       "99999       99790     27  ffd5620bcbf69023    -8.10  1981.84   \n",
       "\n",
       "                             date                 description  \\\n",
       "0      2017-04-24 11:00:00.000000                      Energy   \n",
       "1      2017-04-24 17:36:55.000000                     Monthly   \n",
       "2      2017-04-25 16:00:00.000000         Credit Card Payment   \n",
       "3      2017-04-27 16:00:00.000000                  Water Bill   \n",
       "4      2017-05-23 17:00:00.000000                      Energy   \n",
       "...                           ...                         ...   \n",
       "99995  2017-05-20 15:50:57.000000  Shopping - Household Goods   \n",
       "99996  2017-05-22 08:00:00.000000                  Water Bill   \n",
       "99997         2017-05-22 09:00:00                      Energy   \n",
       "99998         2017-05-22 20:47:15                     Bar/Pub   \n",
       "99999         2017-05-25 19:43:35   Groceries - Food & Drinks   \n",
       "\n",
       "                   flag                id    type  age            datetime  \\\n",
       "0          Utility Bill  38a21d894127b49d   Debit   -1 2017-04-24 11:00:00   \n",
       "1                Income  3941e50e4613a49a  Credit   -1 2017-04-24 17:36:55   \n",
       "2           Credit Card  c09e8105dcfc85b7   Debit   -1 2017-04-25 16:00:00   \n",
       "3          Utility Bill  81e4ffc8df86920e   Debit   -1 2017-04-27 16:00:00   \n",
       "4          Utility Bill  c0ddd8f8a923d40f   Debit   -1 2017-05-23 17:00:00   \n",
       "...                 ...               ...     ...  ...                 ...   \n",
       "99995  Card Transaction  908ac96c72f6c3b7   Debit   -1 2017-05-20 15:50:57   \n",
       "99996      Utility Bill  66d16692309a0738   Debit   -1 2017-05-22 08:00:00   \n",
       "99997      Utility Bill  b71e06b7164af1e3   Debit   -1 2017-05-22 09:00:00   \n",
       "99998  Card Transaction  8a28f7eeff2dbabb   Debit   -1 2017-05-22 20:47:15   \n",
       "99999  Card Transaction  cf50bb5dcb3d3d32   Debit   -1 2017-05-25 19:43:35   \n",
       "\n",
       "       month  day  dow  year  dtme  \\\n",
       "0          4   24    0  2017     6   \n",
       "1          4   24    0  2017     6   \n",
       "2          4   25    1  2017     5   \n",
       "3          4   27    3  2017     3   \n",
       "4          5   23    1  2017     8   \n",
       "...      ...  ...  ...   ...   ...   \n",
       "99995      5   20    5  2017    11   \n",
       "99996      5   22    0  2017     9   \n",
       "99997      5   22    0  2017     9   \n",
       "99998      5   22    0  2017     9   \n",
       "99999      5   25    3  2017     6   \n",
       "\n",
       "                                                   tcode    td  \n",
       "0                            Energy__Utility Bill__Debit   0.0  \n",
       "1                                Monthly__Income__Credit   0.0  \n",
       "2                Credit Card Payment__Credit Card__Debit   0.0  \n",
       "3                        Water Bill__Utility Bill__Debit   2.0  \n",
       "4                            Energy__Utility Bill__Debit  26.0  \n",
       "...                                                  ...   ...  \n",
       "99995  Shopping - Household Goods__Card Transaction__...   0.0  \n",
       "99996                    Water Bill__Utility Bill__Debit   1.0  \n",
       "99997                        Energy__Utility Bill__Debit   0.0  \n",
       "99998                   Bar/Pub__Card Transaction__Debit   0.0  \n",
       "99999  Groceries - Food & Drinks__Card Transaction__D...   2.0  \n",
       "\n",
       "[100000 rows x 19 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_df = pd.read_csv(f\"stored_data/final_df-{ds_suffix}.csv\", parse_dates=[\"datetime\"])\n",
    "real_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<my_lib.BanksformerGen.Transformer at 0x7fdc8c1bdf10>,\n",
       " <my_lib.BanksformerGen.Transformer at 0x7fdc61c1c2b0>,\n",
       " <my_lib.BanksformerGen.Transformer at 0x7fdc63ea4f10>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_seqs_to_generate = 5000\n",
    "\n",
    "\n",
    "start_date_opts = real_df.groupby(\"account_id\")[\"datetime\"].min().dt.date.to_list()\n",
    "# start_date_opts = [START_DATE + datetime.timedelta(i) for i in range(365)]\n",
    "\n",
    "start_dates = np.random.choice(start_date_opts, size=n_seqs_to_generate)\n",
    "\n",
    "\n",
    "seq_ages = np.random.choice(attributes, size=n_seqs_to_generate)\n",
    "seq_ages\n",
    "\n",
    "all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin with  v2b__nld_4-dm_128-nh_2-i_0-dr_0.1-opt_adam-lwi_0-bs_64\n",
      "took 233.96882581710815 secs to generate\n",
      "Wrote df to generated_data/gen_v2b__nld_4-dm_128-nh_2-i_0-dr_0__1-opt_adam-lwi_0-bs_64--cond-len_20-v2.csv\n",
      "Begin with  v2b__nld_4-dm_128-nh_2-i_1-dr_0.1-opt_adam-lwi_0-bs_64\n",
      "took 234.67804718017578 secs to generate\n",
      "Wrote df to generated_data/gen_v2b__nld_4-dm_128-nh_2-i_1-dr_0__1-opt_adam-lwi_0-bs_64--cond-len_20-v2.csv\n",
      "Begin with  v2b__nld_4-dm_128-nh_2-i_2-dr_0.1-opt_adam-lwi_0-bs_64\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_models)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    transformer = all_models[i]\n",
    "    \n",
    "    print(\"Begin with \", transformer.id_str)\n",
    "\n",
    "    \n",
    "    save_as = f\"generated_data/gen_{id_str_to_folder(transformer.id_str)}--{nb_id}-len_{seq_len}-v2.csv\"\n",
    "    \n",
    "    if os.path.exists(save_as):\n",
    "        print(\"**** Skipping because file already exists. File name =\", save_as, \"\\n\\n\\n\")\n",
    "\n",
    "    start = time.time()\n",
    "    full_df, seqs, raw = generate_seqs(length= seq_len, \n",
    "                                       ages=seq_ages, \n",
    "                                       start_dates= start_dates, \n",
    "                                       return_single_df=True,\n",
    "                                      greedy_dates=True)\n",
    "    \n",
    "    full_df[\"account_id\"] = np.arange(len(full_df)) // seq_len\n",
    "    \n",
    "    for field in CAT_FIELDS:\n",
    "        field = field.replace(\"_num\", \"\")\n",
    "        full_df[field] = full_df[field + \"_num\"].apply(lambda x: get_code_from_num(data_encoder, field, x))\n",
    "        \n",
    "\n",
    "    print(f\"took {time.time() - start} secs to generate\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    full_df.to_csv(save_as)\n",
    "    print(\"Wrote df to\", save_as)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
