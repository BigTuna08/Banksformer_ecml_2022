{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c171f062-f77e-49e6-aadf-21bf27a003b2",
   "metadata": {},
   "source": [
    "# Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc2b97-380b-4f55-a28b-23bd8ff29f8f",
   "metadata": {},
   "source": [
    "This notebook computes a large number of data quality metrics between files in the generated data folder and the real dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "distinguished-klein",
   "metadata": {},
   "source": [
    "For each transaction, we need:\n",
    "1 - 'datetime' \n",
    "2 - 'raw_amount'\n",
    "3 - either \n",
    "  -- (A) columns for each code in 'cat_code_fields' or \n",
    "  -- (B) tcode column which is a concatination of the codes in 'cat_code_fields'\n",
    "  -- (C) tcode column with 'shortnames' and information in 'codenames.py' for converting (deprecated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-munich",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "central-giving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to real dataset\n",
    "real_data_loc = \"real_data/final_df--uk.csv\"\n",
    "\n",
    "# path to folder containing generated dataset\n",
    "gen_data_folder = \"generated_data/\"  \n",
    "\n",
    "# path to folder for saving results objects\n",
    "results_folder = \"results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-venezuela",
   "metadata": {},
   "source": [
    "##### Continous metrics"
   ]
  },
  {
   "cell_type": "raw",
   "id": "pleasant-worse",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-combat",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial-belfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from mylib.metrics import compute_all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-madison",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-nickel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "protecting-momentum",
   "metadata": {},
   "source": [
    "# Setup dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "champion-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time  = time.time()\n",
    "new_time = start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454996a8-2d16-4cf4-84f5-b477d995df8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if results_folder.replace(\"/\", \"\")  in os.listdir():\n",
    "    display(os.listdir(results_folder))\n",
    "else:\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disciplinary-tennis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Begining to process: bf.csv\n",
      "Took  242.857 secs since notebook start. ( 242.857 since last update) \n",
      "\n",
      "Begining to process: dg.csv\n",
      "Took  488.242 secs since notebook start. ( 245.385 since last update) \n",
      "\n",
      "Begining to process: tg.csv\n",
      "Took  716.018 secs since notebook start. ( 227.776 since last update) \n"
     ]
    }
   ],
   "source": [
    "failed_on = []\n",
    "\n",
    "for fname in sorted(os.listdir(gen_data_folder)):\n",
    "    \n",
    "    if not \".csv\" in fname:\n",
    "        continue \n",
    "        \n",
    "    result_fname = fname.replace(\".csv\", \".result\")\n",
    "    print()\n",
    "        \n",
    "    if result_fname in os.listdir(results_folder):\n",
    "        print(\"Skipping, result already exists for:\", result_fname)\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    print(\"Begining to process:\", fname)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        gen_data_loc = os.path.join(gen_data_folder, fname)\n",
    "        result_loc = os.path.join(results_folder, result_fname)\n",
    "\n",
    "        full_result = compute_all_metrics(real_data_loc, gen_data_loc)\n",
    "\n",
    "        full_result.save(result_loc)\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        failed_on.append((fname, e))\n",
    "        print(f\"Failed to update: {fname}. ({e})\", )\n",
    "    \n",
    "    prev_time = new_time \n",
    "    new_time = time.time()\n",
    "    print(f\"Took {new_time - start_time: .3f} secs since notebook start. ({new_time - prev_time: .3f} since last update) \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
